# Scenario IV: smaller effect, point prior {#scenarioIV}


## Details

In this scenario an alternative effect size of $\delta = 0.2$ with
point prior distribution is investigated. 
This smaller effect size should lead to larger sample sizes than
in scenario I.
The null hypothesis is $\delta \leq 0$.
Currently, `adoptr` only supports normal distributed data what is widely spread
in the development of adaptive designs. 
We protect the one-sided type one error rate at $\alpha = 0.025$ and require
the power of the design to be at least $1 - \beta = 0.8$ in the first
case and vary these values in the following cases.



### Data distribution

Two-armed trial with normally distributed test statistic
```{r}
datadist <- Normal(two_armed = TRUE)
```


### Null hypothesis

The null hypothesis is $\mathcal{H}_0:\delta \leq 0$
```{r}
H_0 <- PointMassPrior(.0, 1)
```


### Prior assumptions
A point mass prior with probability mass on $\delta = 0.2$ is assumed.
```{r}
prior <- PointMassPrior(.2, 1)
```




## Variant IV-1: Minimizing Expected Sample Size under Point Prior {#variantIV_1}

### Objective

Expected sample size under the respective prior is minimized, i.e.,
$\boldsymbol{E}\big[n(\mathcal{D})\big]$.
```{r objective}
ess <- expected(ConditionalSampleSize(datadist, prior))
```


### Constrains

The type one error rate is controlled at $0.025$ on the boundary of the 
null hypothesis.
```{r toer-constraint}
toer_cnstr <- expected(ConditionalPower(datadist, H_0)) <= .025
```

Power  must be larger than $0.8$.
```{r power}
pow_cnstr <- expected(ConditionalPower(datadist, prior)) >= .8
```


### Initial Design

`adoptr` requires the definition of an initial design for optimization. 
We start with a group-sequential design from the package `rpact` that
fulfills these constraints and is used later for comparison.
The order of integration is set to $5$.


```{r}
order <- 5L 

init_design_gs <- rpact_design(0.2, 0.025, 0.8, TRUE, order)
```


### Optimization 

The optimal design is computed in three variants: two-stage, group-sequential
and one-stage.
The input only differs with regard to the initial design.
The optimal group-sequential design is used as initial design to
compute the optimal two-stage design.

```{r}
opt_design <- function(initial_design) {
    minimize(
        ess,
        subject_to(
            toer_cnstr,
            pow_cnstr
        ),
        initial_design = initial_design,
        opts = opts
    )
}

opt1_gs <- opt_design(init_design_gs)
opt1_ts <- opt_design(TwoStageDesign(opt1_gs$design))
opt1_os <- opt_design(OneStageDesign(500, 2.0))
```



### Test Cases

Check if the optimization algorithm converged in all cases.
```{r}
iters <- sapply(list(opt1_ts, opt1_gs, opt1_os), 
                function(x) x$nloptr_return$iterations)

print(iters)

testthat::expect_true(all(iters < opts$maxeval))
```



Type one error rate constraint is tested for the three designs.
Due to numerical issues we allow a realtive error of $1\%$.
```{r}
tmp     <- sapply(list(opt1_ts, opt1_gs, opt1_os),  
                  function(x) sim_pr_reject(x$design, .0, datadist))
df_toer <- data.frame(
    toer = as.numeric(tmp[1, ]),
    se   = as.numeric(tmp[2, ])
)
rm(tmp)

testthat::expect_true(all(df_toer$toer <= .025*(1.01)))

df_toer
```


The power constraint can also be tested via simulation.
Due to numerical issues we allow a realtive error of $1\%$.
```{r}
tmp     <- sapply(list(opt1_ts, opt1_gs, opt1_os),  
                  function(x) sim_pr_reject(x$design, .2, datadist))
df_pow <- data.frame(
    pow  = as.numeric(tmp[1, ]),
    se   = as.numeric(tmp[2, ])
)
rm(tmp)

testthat::expect_true(all(df_pow$pow >= .8 * (1 - 0.01)))

df_pow
```


The expected sample sizes should be ordered in a specific way.
```{r}
testthat::expect_gte(
    evaluate(ess, opt1_os$design),
    evaluate(ess, opt1_gs$design)
)

testthat::expect_gte(
    evaluate(ess, init_design_gs),
    evaluate(ess, opt1_gs$design)
)

testthat::expect_gte(
    evaluate(ess, opt1_gs$design),
    evaluate(ess, opt1_ts$design)
)
```


The expected sample size of the optimal designs is simulated and compared
to the outomce of `adoptr::evaluate()`.
The tolerance is set to $0.5$ what is due to rounding one patient per group
in the worst case.
```{r}
ess_0 <- expected(ConditionalSampleSize(datadist, H_0))

testthat::expect_equal(
    sim_n(opt1_os$design, .0, datadist)$n,
    evaluate(ess_0, opt1_os$design),
    tolerance = .5
)

testthat::expect_equal(
    sim_n(opt1_gs$design, .0, datadist)$n,
    evaluate(ess_0, opt1_gs$design),
    tolerance = .5
)

testthat::expect_equal(
    sim_n(opt1_ts$design, .0, datadist)$n,
    evaluate(ess_0, opt1_ts$design),
    tolerance = .5
)
```


Additionally, the sample sizes under the point prior are compared.
```{r}
testthat::expect_equal(
    sim_n(opt1_os$design, .2, datadist)$n,
    evaluate(ess, opt1_os$design),
    tolerance = .5
)

testthat::expect_equal(
    sim_n(opt1_gs$design, .2, datadist)$n,
    evaluate(ess, opt1_gs$design),
    tolerance = .5
)

testthat::expect_equal(
    sim_n(opt1_ts$design, .2, datadist)$n,
    evaluate(ess, opt1_ts$design),
    tolerance = .5
)
```

The $n_2$ function of the optimal two-stage design is expected to be 
monotonously decreasing.

```{r}
testthat::expect_equal(
    sign(diff(opt1_ts$design@n2_pivots)),
    rep(-1, (order - 1))
)
```




## Variant IV-2: Increase Power {#variantIV_2}

### Objective

The objective remains the same as before. 

### Constrains

The power is increased to $90\%$.

```{r}
pow_cnstr_2 <- expected(ConditionalPower(datadist, prior)) >= .9
```


### Initial Design

The initial design is updated to a group-sequential design that fulfills
the new power constraint.

```{r}
order <- 5L 

init_design_2_gs <- rpact_design(0.2, 0.025, 0.9, TRUE, order)

init_design_2    <- TwoStageDesign(init_design_2_gs)
```


### Optimization 

The optimal two-stage design is computed. 

```{r}
opt_design <- function(initial_design) {
    minimize(
        ess,
        subject_to(
            toer_cnstr,
            pow_cnstr_2
        ),
        initial_design = initial_design,
        opts = opts
    )
}

opt2_ts <- opt_design(init_design_2)
opt2_gs <- opt_design(init_design_2_gs)
opt2_os <- opt_design(OneStageDesign(500, 2.0))
```



### Test Cases

Check if the optimization algorithm converged in all cases.
```{r}
iters <- sapply(list(opt2_ts, opt2_gs, opt2_os), 
                function(x) x$nloptr_return$iterations)

print(iters)

testthat::expect_true(all(iters < opts$maxeval))
```



Type one error rate constraint is tested for the three designs.
Due to numerical issues we allow a realtive error of $1\%$.
```{r}
tmp     <- sapply(list(opt2_ts, opt2_gs, opt2_os),  
                  function(x) sim_pr_reject(x$design, .0, datadist))
df_toer <- data.frame(
    toer = as.numeric(tmp[1, ]),
    se   = as.numeric(tmp[2, ])
)
rm(tmp)

testthat::expect_true(all(df_toer$toer <= .025*(1.01)))

df_toer
```


The power constraint can also be tested via simulation.
Due to numerical issues we allow a realtive error of $1\%$.
```{r}
tmp     <- sapply(list(opt2_ts, opt2_gs, opt2_os),  
                  function(x) sim_pr_reject(x$design, .2, datadist))
df_pow <- data.frame(
    pow  = as.numeric(tmp[1, ]),
    se   = as.numeric(tmp[2, ])
)
rm(tmp)

testthat::expect_true(all(df_pow$pow >= .9 * (1 - 0.01)))

df_pow
```


The expected sample sizes should be ordered in a specific way.
```{r}
testthat::expect_gte(
    evaluate(ess, opt2_os$design),
    evaluate(ess, opt2_gs$design)
)

testthat::expect_gte(
    evaluate(ess, init_design_2_gs),
    evaluate(ess, opt2_gs$design)
)

testthat::expect_gte(
    evaluate(ess, opt2_gs$design),
    evaluate(ess, opt2_ts$design)
)
```


The expected sample size of the optimal designs is simulated and compared
to the outomce of `adoptr::evaluate()`.
The tolerance is set to $0.5$ what is due to rounding one patient per group
in the worst case.
```{r}
ess_0 <- expected(ConditionalSampleSize(datadist, H_0))

testthat::expect_equal(
    sim_n(opt2_os$design, .0, datadist)$n,
    evaluate(ess_0, opt2_os$design),
    tolerance = .5
)

testthat::expect_equal(
    sim_n(opt2_gs$design, .0, datadist)$n,
    evaluate(ess_0, opt2_gs$design),
    tolerance = .5
)

testthat::expect_equal(
    sim_n(opt2_ts$design, .0, datadist)$n,
    evaluate(ess_0, opt2_ts$design),
    tolerance = .5
)
```


Additionally, the sample sizes under the point prior are compared.
```{r}
testthat::expect_equal(
    sim_n(opt2_os$design, .2, datadist)$n,
    evaluate(ess, opt2_os$design),
    tolerance = .5
)

testthat::expect_equal(
    sim_n(opt2_gs$design, .2, datadist)$n,
    evaluate(ess, opt2_gs$design),
    tolerance = .5
)

testthat::expect_equal(
    sim_n(opt2_ts$design, .2, datadist)$n,
    evaluate(ess, opt2_ts$design),
    tolerance = .5
)
```


The $n_2$ function of the optimal two-stage design is expected to be 
monotonously decreasing.

```{r}
testthat::expect_equal(
    sign(diff(opt2_ts$design@n2_pivots)),
    rep(-1, (order - 1))
)
```



## Variant IV-3: Increase Type One Error rate {#variantIV_3}

### Objective

Expected sample size under the point prior is minimized and has already been
defined.

### Constrains

The maximal type one error rate is increased to $5\%$.

```{r}
toer_cnstr_2 <- expected(ConditionalPower(datadist, H_0)) <= .05
```

### Initial Design

The initial design is updated to a group-sequential design that fulfills
the new type one error rate constraint.

```{r}
order <- 5L 

init_design_3_gs <- rpact_design(0.2, 0.05, 0.9, TRUE, order)

init_design_3    <- TwoStageDesign(init_design_3_gs)
```

### Optimization 

The optimal two-stage design is computed. 

```{r}
opt_design <- function(initial_design) {
    minimize(
        ess,
        subject_to(
            toer_cnstr_2,
            pow_cnstr_2
        ),
        initial_design = initial_design,
        opts = opts
    )
}

opt3_ts <- opt_design(init_design_3)
opt3_gs <- opt_design(init_design_3_gs)
opt3_os <- opt_design(OneStageDesign(500, 2.0))
```



### Test Cases

Check if the optimization algorithm converged in all cases.
```{r}
iters <- sapply(list(opt3_ts, opt3_gs, opt3_os), 
                function(x) x$nloptr_return$iterations)

print(iters)

testthat::expect_true(all(iters < opts$maxeval))
```



Type one error rate constraint is tested for the three designs.
Due to numerical issues we allow a realtive error of $1\%$.
```{r}
tmp     <- sapply(list(opt3_ts, opt3_gs, opt3_os),  
                  function(x) sim_pr_reject(x$design, .0, datadist))
df_toer <- data.frame(
    toer = as.numeric(tmp[1, ]),
    se   = as.numeric(tmp[2, ])
)
rm(tmp)

testthat::expect_true(all(df_toer$toer <= .05*(1.01)))

df_toer
```


The power constraint can also be tested via simulation.
Due to numerical issues we allow a realtive error of $1\%$.
```{r}
tmp     <- sapply(list(opt3_ts, opt3_gs, opt3_os),  
                  function(x) sim_pr_reject(x$design, .2, datadist))
df_pow <- data.frame(
    pow  = as.numeric(tmp[1, ]),
    se   = as.numeric(tmp[2, ])
)
rm(tmp)

testthat::expect_true(all(df_pow$pow >= .9 * (1 - 0.01)))

df_pow
```


The expected sample sizes should be ordered in a specific way.
```{r}
testthat::expect_gte(
    evaluate(ess, opt3_os$design),
    evaluate(ess, opt3_gs$design)
)

testthat::expect_gte(
    evaluate(ess, init_design_3_gs),
    evaluate(ess, opt3_gs$design)
)

testthat::expect_gte(
    evaluate(ess, opt3_gs$design),
    evaluate(ess, opt3_ts$design)
)
```


The expected sample size of the optimal designs is simulated and compared
to the outomce of `adoptr::evaluate()`.
The tolerance is set to $0.5$ what is due to rounding one patient per group
in the worst case.
```{r}
ess_0 <- expected(ConditionalSampleSize(datadist, H_0))

testthat::expect_equal(
    sim_n(opt3_os$design, .0, datadist)$n,
    evaluate(ess_0, opt3_os$design),
    tolerance = .5
)

testthat::expect_equal(
    sim_n(opt3_gs$design, .0, datadist)$n,
    evaluate(ess_0, opt3_gs$design),
    tolerance = .5
)

testthat::expect_equal(
    sim_n(opt3_ts$design, .0, datadist)$n,
    evaluate(ess_0, opt3_ts$design),
    tolerance = .5
)
```


Additionally, the sample sizes under the point prior are compared.
```{r}
testthat::expect_equal(
    sim_n(opt3_os$design, .2, datadist)$n,
    evaluate(ess, opt3_os$design),
    tolerance = .5
)

testthat::expect_equal(
    sim_n(opt3_gs$design, .2, datadist)$n,
    evaluate(ess, opt3_gs$design),
    tolerance = .5
)

testthat::expect_equal(
    sim_n(opt3_ts$design, .2, datadist)$n,
    evaluate(ess, opt3_ts$design),
    tolerance = .5
)
```


The $n_2$ function of the optimal two-stage design is expected to be 
monotonously decreasing.

```{r}
testthat::expect_equal(
    sign(diff(opt3_ts$design@n2_pivots)),
    rep(-1, (order - 1))
)
```





## Plot Two-Stage Designs
The optimal two-stage designs stemming from the three different variants
are plotted together. 


```{r, echo = FALSE}
z1 <- seq(-.5, 3, by = .01)

tibble(
    constraints  = c("TOER<=0.025, Power>=0.8",
                     "TOER<=0.025, Power>=0.9",
                     "TOER<=0.050, Power>=0.9"), 
    design = list(opt1_ts$design, opt2_ts$design, opt3_ts$design)
) %>% 
    group_by(constraints) %>% 
    do(
        z1 = z1,
        n  = adoptr::n(.$design[[1]], z1),
        c2 = c2(.$design[[1]], z1)
    ) %>% 
    unnest() %>% 
    mutate(
        section = ifelse(
            is.finite(c2), 
            "continuation", 
            ifelse(c2 == -Inf, "efficacy", "futility")
        )
    ) %>% 
    gather(variable, value, n, c2) %>% 
    ggplot(aes(z1, value, color = constraints)) +
        geom_line(aes(group = interaction(section, constraints))) + 
        facet_wrap(~variable, scales = "free_y") +
        theme_bw() +
        scale_color_manual(
          values = c(rgb(0,74,111, maxColorValue = 255),
                                    rgb(0,159,227, maxColorValue = 255),
                                    rgb(230,121,0, maxColorValue = 255))) +
        theme(
            panel.grid = element_blank()
        )
```

