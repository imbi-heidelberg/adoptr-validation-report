[["index.html", "Validation Report for adoptr package 1 Introduction 1.1 Preliminaries 1.2 Scope 1.3 Validation Scenarios 1.4 Technical Setup", " Validation Report for adoptr package Kevin Kunzmann, Maximilian Pilz &amp; Nico Bruder 2023-12-15 1 Introduction This work is licensed under the CC-BY-SA 4.0 license 1.1 Preliminaries R package validation for regulatory environments can be a tedious endeavour. The authors firmly believe that under the current regulation, there is no such thing as a ‘validated R package’: validation is by definition a process conducted by the user. This validation report merely aims at facilitating validation of adoptr as much as possible. No warranty whatsoever as to the correctness of adoptr nor the completeness of the validation report are given by the authors. We assume that the reader is familiar with the notation an theoretical background of adoptr. Otherwise, the following resources might be of help: adoptr online documentation at https://kkmann.github.io/adoptr/ paper on the theoretical background of the core adoptr functionality (Pilz et al. 2019) a general overview on adaptive designs is given in (Bauer et al. 2015) a more extensive treatment of the subject in (Wassmer and Brannath 2016). 1.2 Scope adoptr itself already makes extensive use of unittesting to ensure correctness of all implemented functions. Yet, due to constraints on the build-time for an R package, the range of scenarios covered in the unittests of adoptr is rather limited. Furthermore, the current R unittesting framework does not permit an easy generation of a human-readable report of the test cases to ascertain coverage and test quality. Therefore, adoptr splits testing in two parts: technical correctness is ensured via an extensive unittesting suit in adoptr itself (aiming to maintain a 100% code coverage). The validation report, however, runs through a wide range of possible application scenarios and ensures plausibility of results as well as consistency with existing methods wherever possible. The report itself is implemented as a collection of Rmarkdown documents allowing to show both the underlying code as well as the corresponding output in a human-readable format. The online version of the report is dynamically re-generated on a weekly basis based on the respective most current version of adoptr on CRAN. The latest result of these builds is available at https://kkmann.github.io/adoptr-validation-report/. To ensure early warning in case of any test-case failures, formal tests are implemented using the testthat package (Wickham, R Studio, and R Core Team 2018). I.e., the combination of using a unittesting framework, a continuous integration, and continuous deployment service leads to an always up-to-date validation report (build on the current R release on Linux). Any failure of the integrated formal tests will cause the build status of the validation report to switch from ‘passing’ to ‘failed’ and the respective maintainer will be notified immediately. 1.2.1 Validating a local installation of adoptr Note that, strictly speaking, the online version of the validation report only provides evidence of the correctness on the respective Travis-CI cloud virtual machine infrastructure using the respective most recent release of R and the most recent versions of the dependencies available on CRAN. In some instances it might therefore be desireable to conduct a local validaton of adoptr. To do so, one should install adoptr with the INSTALL_opts option to include tests and invoke the test suit locally via install.packages(&quot;adoptr&quot;, INSTALL_opts = c(&quot;--install-tests&quot;)) tools::testInstalledPackage(&quot;adoptr&quot;, types = c(&quot;examples&quot;, &quot;tests&quot;)) Upon passing the test suit successfully, the validation report can be build locally. To do so, first clone the entire source directory and switch to the newly created folder git clone https://github.com/kkmann/adoptr-validation-report.git cd adoptr-validation-report Make sure that all packages required for building the report are available, i.e., install all dependencies listed in the top-level DESCRIPTION file, e.g., install.packages(c( &quot;adoptr&quot;, &quot;tidyverse&quot;, &quot;bookdown&quot;, &quot;rpact&quot;, &quot;testthat&quot;, &quot;pwr&quot; ) ) The book can then be build using the terminal command Rscript -e &#39;bookdown::render_book(&quot;index.Rmd&quot;, output_format = &quot;all&quot;)&#39; or directly from R via bookdown::render_book(&quot;index.Rmd&quot;, output_format = &quot;all&quot;) This produces a new folder _book with the html and pdf versions of the report. 1.3 Validation Scenarios 1.3.1 Scenario I: Large effect, point prior This is the default scenario. Data distribution: Two-armed trial with normally distributed test statistic Prior: \\(\\delta\\sim\\textbf{1}_{\\delta=0.4}\\) Null hypothesis: \\(\\mathcal{H}_0:\\delta \\leq 0\\) 1.3.1.1 Variant I.1: Minimizing Expected Sample Size under the Alternative Objective: \\(ESS := \\boldsymbol{E}\\big[n(X_1)\\,|\\,\\delta=0.4\\big]\\) Constraints: \\(Power := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.4\\big] \\geq 0.8\\) \\(TOER := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.0\\big] \\leq 0.025\\) Three variants: two-stage, group-sequential, one-stage. Formal tests: Number of iterations are checked against default maximum to ensure proper convergence. All three adoptr variants (two-stage, group-sequential, one-stage) comply with constraints. Internally validated by testing vs. simulated values of the power curve at respective points. Is \\(n()\\) of the optimal two-stage design monotonously decreasing on continuation area? \\(ESS\\) of optimal two-stage design is lower than \\(ESS\\) of optimal group-sequential one and that is in turn lower than the one of the optimal one-stage design. \\(ESS\\) of optimal group-sequential design is lower than \\(ESS\\) of externally computed group-sequential design using the rpact package. Are the \\(ESS\\) values obtained from simulation the same as the ones obtained by using numerical integration via adoptr::evaluate? 1.3.1.2 Variant I.2: Minimizing Expected Sample Size under the Null Hypothesis Objective: \\(ESS := \\boldsymbol{E}\\big[n(X_1)\\,|\\,\\color{red}{\\delta=0.0}\\big]\\) Constraints: \\(Power := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.4\\big] \\geq 0.8\\) \\(TOER := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.0\\big] \\leq 0.025\\) Formal tests: Number of iterations are checked against default maximum to ensure proper convergence. Validate constraint compliance by testing vs. simulated values of the power curve at respective points. \\(n()\\) of optimal design is monotonously increasing on continuation area. \\(ESS\\) of optimal two-stage design is lower than \\(ESS\\) of externally computed group-sequential design using the rpact package. Are the \\(ESS\\) values obtained from simulation the same as the ones obtained by using numerical integration via adoptr::evaluate? 1.3.1.3 Variant I.3: Conditional Power Constraint Objective: \\(ESS := \\boldsymbol{E}\\big[n(X_1)\\,|\\,\\delta=0.4\\big]\\) Constraints: \\(Power := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.4\\big] \\geq 0.8\\) \\(TOER := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.0\\big] \\leq 0.025\\) \\(CP := \\color{red}{\\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.4, X_1 = x_1\\big] \\geq 0.7}\\) for all \\(x_1\\in(c_1^f, c_1^e)\\) Formal tests: Number of iterations are checked against default maximum to ensure proper convergence. Check \\(Power\\) and \\(TOER\\) constraints with simulation. Check \\(CP\\) constraint on 25 different values of \\(x_1\\) in \\([c_1^f, c_1^e]\\) Are the \\(CP\\) values at the 25 test-pivots obtained from simulation the same as the ones obtained by using numerical integration via adoptr::evaluate? Is \\(ESS\\) of optimal two-stage design with \\(CP\\) constraint higher than \\(ESS\\) of optimal two-stage design without this constraint? 1.3.2 Scenario II: Large effect, Gaussian prior Similar scope to Scenario I, but with a continuous Gaussian prior on \\(\\delta\\). Data distribution: Two-armed trial with normally distributed test statistic Prior: \\(\\delta\\sim\\mathcal{N}(0.4, .3)\\) Null hypothesis: \\(\\mathcal{H}_0:\\delta \\leq 0\\) 1.3.2.1 Variant II.1: Minimizing Expected Sample Size Objective: \\(ESS := \\boldsymbol{E}\\big[n(X_1)\\big]\\) Constraints: \\(Power := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta&gt; 0.0\\big] \\geq 0.8\\) \\(TOER := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.0\\big] \\leq 0.025\\) Three variants: two-stage, group-sequential, one-stage. Formal tests: Number of iterations are checked against default maximum to ensure proper convergence. All designs comply with type one error rate constraints (tested via simulation). \\(ESS\\) of optimal two-stage design is lower than \\(ESS\\) of optimal group-sequential one and that is in turn lower than the one of the optimal one-stage design. 1.3.2.2 Variant II.2: Minimizing Expected Sample Size under the Null hypothesis Objective: \\(ESS := \\boldsymbol{E}\\big[n(X_1)\\,|\\,\\color{red}{\\delta\\leq 0}\\big]\\) Constraints: \\(Power := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta&gt; 0.0\\big] \\geq 0.8\\) \\(TOER := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.0\\big] \\leq 0.025\\) Formal tests: Number of iterations are checked against default maximum to ensure proper convergence. Does the design comply with \\(TOER\\) constraint (via simulation)? Is \\(ESS\\) lower than expected sample size under the null hypothesis for the optimal two stage design from Variant II-1? 1.3.2.3 Variant II.3: Condtional Power Constraint Objective: \\(ESS := \\boldsymbol{E}\\big[n(X_1)\\big]\\) Constraints: \\(Power := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta&gt;0.0\\big] \\geq 0.8\\) \\(TOER := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.0\\big] \\leq 0.025\\) \\(CP := \\color{red}{\\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta&gt; 0.0, X_1 = x_1\\big] \\geq 0.7}\\) for all \\(x_1\\in(c_1^f, c_1^e)\\) Formal tests: Number of iterations are checked against default maximum to ensure proper convergence. Check \\(TOER\\) constraint with simulation. Check \\(CP\\) constraint on three different values of \\(x_1\\) in \\((c_1^f, c_1^e)\\) Is \\(ESS\\) of optimal two-stage design with \\(CP\\) constraint higher than \\(ESS\\) of optimal two-stage design without the constraint? 1.3.3 Scenario III: Large effect, uniform prior Data distribution: Two-armed trial with normally distributed test statistic Prior: sequence of uniform distributions \\(\\delta\\sim\\operatorname{Unif}(0.4 - \\Delta_i, 0.4 + \\Delta_i)\\) around \\(0.4\\) with \\(\\Delta_i=(3 - i)/10\\) for \\(i=0\\ldots 3\\). I.e., for \\(\\Delta_3=0\\) reduces to a point prior on \\(\\delta=0.4\\). Null hypothesis: \\(\\mathcal{H}_0:\\delta \\leq 0\\) 1.3.3.1 Variant III.1: Convergence under Prior Concentration Objective: \\(ESS := \\boldsymbol{E}\\big[n(X_1)\\big]\\) Constraints: \\(Power := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta&gt;0.0\\big] \\geq 0.8\\) \\(TOER := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.0\\big] \\leq 0.025\\) Formal tests: Number of iterations are checked against default maximum to ensure proper convergence. Simulated type one error rate is compared to \\(TOER\\) constraint for each design. \\(ESS\\) decreases with prior variance. Additionally, the designs are compared graphically. Inspect the plot to see convergence pattern. 1.3.4 Scenario IV: Smaller effect size, larger trials 1.3.4.1 Variant IV.1: Minimizing Expected Sample Size under the Alternative Objective: \\(ESS := \\boldsymbol{E}\\big[n(X_1)\\,|\\,\\delta=0.2\\big]\\) Constraints: \\(Power := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.2\\big] \\geq 0.8\\) \\(TOER := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.0\\big] \\leq 0.025\\) Three variants: two-stage, group-sequential, one-stage. Formal tests: Number of iterations are checked against default maximum to ensure proper convergence. All three adoptr variants (two-stage, group-sequential, one-stage) comply with constraints. Internally validated by testing vs. simulated values of the power curve at respective points. \\(ESS\\) of optimal two-stage design is lower than \\(ESS\\) of optimal group-sequential one and that is in turn lower than the one of the optimal one-stage design. \\(ESS\\) of optimal group-sequential design is lower than \\(ESS\\) of externally computed group-sequential design using the rpact package. Are the \\(ESS\\) values obtained from simulation the same as the ones obtained by using numerical integration via adoptr::evaluate? Is \\(n()\\) of the optimal two-stage design monotonously decreasing on continuation area? 1.3.4.2 Variant IV.2: Increasing Power Objective: \\(ESS := \\boldsymbol{E}\\big[n(X_1)\\,|\\,\\delta=0.2\\big]\\) Constraints: \\(Power := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.2\\big] \\geq \\color{red}{0.9}\\) \\(TOER := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.0\\big] \\leq 0.025\\) Three variants: two-stage, group-sequential, one-stage. Formal tests: Number of iterations are checked against default maximum to ensure proper convergence. Does the design respect all constraints (via simulation)? \\(ESS\\) of optimal two-stage design is lower than \\(ESS\\) of optimal group-sequential one and that is in turn lower than the one of the optimal one-stage design. \\(ESS\\) of optimal group-sequential design is lower than \\(ESS\\) of externally computed group-sequential design using the rpact package. Are the \\(ESS\\) values obtained from simulation the same as the ones obtained by using numerical integration via adoptr::evaluate? Is \\(n()\\) of the optimal two-stage design monotonously decreasing on continuation area? 1.3.4.3 Variant IV.3: Increasing Maximal Type One Error Rate Objective: \\(ESS := \\boldsymbol{E}\\big[n(X_1)\\,|\\,\\delta=0.2\\big]\\) Constraints: \\(Power := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.2\\big] \\geq 0.8\\) \\(TOER := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.0\\big] \\leq \\color{red}{0.05}\\) Three variants: two-stage, group-sequential, one-stage. Formal tests: Number of iterations are checked against default maximum to ensure proper convergence. Does the design respect all constraints (via simulation)? \\(ESS\\) of optimal two-stage design is lower than \\(ESS\\) of optimal group-sequential one and that is in turn lower than the one of the optimal one-stage design. \\(ESS\\) of optimal group-sequential design is lower than \\(ESS\\) of externally computed group-sequential design using the rpact package. Are the \\(ESS\\) values obtained from simulation the same as the ones obtained by using numerical integration via adoptr::evaluate? Is \\(n()\\) of the optimal two-stage design monotonously decreasing on continuation area? 1.3.5 Scenario V: Single-arm design, medium effect size Data distribution: trial with normally distributed test statistic Prior: \\(\\delta\\sim\\delta_{0.3}\\) Null hypothesis: \\(\\mathcal{H}_0:\\delta \\leq 0\\) 1.3.5.1 Variant V.1: Sensitivity to Integration Order Objective: \\(ESS := \\boldsymbol{E}\\big[n(X_1)\\,|\\,\\delta=0.3\\big]\\) Constraints: \\(Power := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\color{red}{\\delta=0.3}\\big] \\geq 0.8\\) \\(TOER := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.0\\big] \\leq 0.025\\) Three variants: integration order 5, 8, 11 two-stage designs. Formal tests: Do all designs converge within the respective iteration limit? Do all designs respect all constraints (via simulation)? 1.3.5.2 Variant V.2: Utility Maximization Objective: \\(\\lambda\\, Power - ESS := \\lambda\\, \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.3\\big] - \\boldsymbol{E}\\big[n(X_1)\\,|\\,\\delta=0.3\\big].\\) for \\(\\lambda = 100\\) and \\(200\\) Constraints: \\(TOER := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.0\\big] \\leq 0.025\\) Formal tests: Number of iterations are checked against default maximum to ensure proper convergence. Do both designs respect the type one error rate constraint (via simulation)? Is the power of the design with larger \\(\\lambda\\) larger? 1.3.5.3 Variant V.3: \\(n_1\\) penalty Objective: \\(ESS := \\boldsymbol{E}\\big[n(X_1)\\,|\\,\\delta=0.3\\big] + \\lambda \\, n_1\\) for \\(\\lambda = 0.05\\) and \\(0.2\\). Constraints: \\(TOER := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.0\\big] \\leq 0.025\\) \\(Power := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.3\\big] \\geq 0.8\\) Formal tests: Number of iterations are checked against default maximum to ensure proper convergence. Do both designs respect the type one error rate and power constraints (via simulation)? Is \\(n_1\\) for the optimal design smaller than the order-5 design in V.1? 1.3.5.4 Variant V.4: \\(n_2\\) penalty Objective: \\(ESS := \\boldsymbol{E}\\big[n(X_1)\\,|\\,\\delta=0.3\\big] + \\lambda\\) AverageN2 for \\(\\lambda = 0.01\\) and \\(0.1\\). Constraints: \\(TOER := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.0\\big] \\leq 0.025\\) \\(Power := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.3\\big] \\geq 0.8\\) Formal tests: Number of iterations are checked against default maximum to ensure proper convergence. Do both designs respect the type one error rate and power constraints (via simulation)? Is the AverageN2 for the optimal design smaller than for the order-5 design in V.1? 1.3.6 Scenario VI: Binomial distribution This scenario investigates the implementation of the binomial distribution. Data distribution: Two-armed trial with binomial distributed outcomes. Thus \\(\\delta := p_E - p_C\\) refers to the rate difference here. The control rate is assumed to equal \\(p_C = 0.3\\). Prior: \\(\\delta\\sim\\textbf{1}_{\\delta=0.2}\\) Null hypothesis: \\(\\mathcal{H}_0:\\delta \\leq 0\\) 1.3.6.1 Variant VI.1: Minimizing Expected Sample Size under the Alternative Objective: \\(ESS := \\boldsymbol{E}\\big[n(X_1)\\,|\\,\\delta=0.2\\big]\\) Constraints: \\(Power := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.2\\big] \\geq 0.9\\) \\(TOER := \\boldsymbol{Pr}\\big[c_2(X_1) &lt; X_2\\,|\\,\\delta=0.0\\big] \\leq 0.025\\) Three variants: two-stage, group-sequential, one-stage. Formal tests: Number of iterations are checked against default maximum to ensure proper convergence. All three adoptr variants (two-stage, group-sequential, one-stage) comply with constraints. Internally validated by testing vs. simulated values of the power curve at respective points. \\(ESS\\) of optimal two-stage design is lower than \\(ESS\\) of optimal group-sequential one and that is in turn lower than the one of the optimal one-stage design. \\(ESS\\) of optimal group-sequential design is lower than \\(ESS\\) of externally computed group-sequential design using the rpact package. Are the \\(ESS\\) values obtained from simulation the same as the ones obtained by using numerical integration via adoptr::evaluate? 1.4 Technical Setup All scenarios are run in a single, shared R session. Required packages are loaded here, the random seed is defined and set centrally, and the default number of iteration is increased to make sure that all scenarios converge properly. Additionally R scripts with convenience functions are sourced here as well. There are three additional functions for this report. rpact_design creates a two-stage design via the package rpact (Wassmer and Pahlke 2018) in the notation of adoptr. sim_pr_reject and sim_n allow to simulate rejection probabilities and expected sample sizes respectively by the adoptr routine simulate. Furthermore, global tolerances for the validation are set. For error rates, a relative deviation of \\(1\\%\\) from the target value is accepted. (Expected) Sample sizes deviations are more liberally accepted up to an absolute deviation of \\(0.5\\). library(adoptr) library(tidyverse) ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.4 ✔ readr 2.1.4 ## ✔ forcats 1.0.0 ✔ stringr 1.5.1 ## ✔ ggplot2 3.4.4 ✔ tibble 3.2.1 ## ✔ lubridate 1.9.3 ✔ tidyr 1.3.0 ## ✔ purrr 1.0.2 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ✖ dplyr::n() masks adoptr::n() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors library(rpact) library(pwr) library(testthat) ## ## Attaching package: &#39;testthat&#39; ## ## The following object is masked from &#39;package:dplyr&#39;: ## ## matches ## ## The following object is masked from &#39;package:purrr&#39;: ## ## is_null ## ## The following objects are masked from &#39;package:readr&#39;: ## ## edition_get, local_edition ## ## The following object is masked from &#39;package:tidyr&#39;: ## ## matches ## ## The following object is masked from &#39;package:adoptr&#39;: ## ## expectation library(tinytex) # load custom functions in folder subfolder &#39;/R&#39; for (nm in list.files(&quot;R&quot;, pattern = &quot;\\\\.[RrSsQq]$&quot;)) source(file.path(&quot;R&quot;, nm)) # define seed value seed &lt;- 42 # define absolute tolerance for error rates tol &lt;- 0.01 # define absolute tolerance for sample sizes tol_n &lt;- 0.5 # define custom tolerance and iteration limit for nloptr opts = list( algorithm = &quot;NLOPT_LN_COBYLA&quot;, xtol_rel = 1e-5, maxeval = 100000 ) References "],["scenarioI.html", "2 Scenario I: large effect, point prior 2.1 Details 2.2 Variant I-1: Minimizing Expected Sample Size under Point Prior 2.3 Variant I-2: Minimizing Expected Sample Size under Null Hypothesis 2.4 Variant I-3: Conditional Power Constraint 2.5 Plot Two-Stage Designs", " 2 Scenario I: large effect, point prior 2.1 Details In this scenario, a classical two-arm trial with normal test statistic and known variance (w.l.o.g. variance of the test statistic is 1). This situation corresponds to a classical \\(z\\)-test for a difference in population means. The null hypothesis is no population mean difference, i.e. \\(\\mathcal{H}_0:\\delta \\leq 0\\). An alternative effect size of \\(\\delta = 0.4\\) with point prior distribution is assumed. Across all variants in this scenario, the one-sided maximal type one error rate is restricted to \\(\\alpha=0.025\\) and the power at the point alternative of \\(\\delta=0.4\\) must be at least \\(0.8\\). # data distribution and hypotheses datadist &lt;- Normal(two_armed = TRUE) H_0 &lt;- PointMassPrior(.0, 1) prior &lt;- PointMassPrior(.4, 1) # define constraints alpha &lt;- 0.025 min_power &lt;- 0.8 toer_cnstr &lt;- Power(datadist, H_0) &lt;= alpha pow_cnstr &lt;- Power(datadist, prior) &gt;= min_power 2.2 Variant I-1: Minimizing Expected Sample Size under Point Prior 2.2.1 Objective Firstly, expected sample size under the alternative (point prior) is minimized, i.e., \\(\\boldsymbol{E}\\big[n(\\mathcal{D})\\big]\\). ess &lt;- ExpectedSampleSize(datadist, prior) 2.2.2 Constraints No additional constraints besides type one error rate and power are considered in this variant. 2.2.3 Initial Designs For this example, the optimal one-stage, group-sequential, and generic two-stage designs are computed. The initial design for the one-stage case is determined heuristically (cf. Scenario III where another initial design is applied on the same situation for stability of initial values). Both the group sequential and the generic two-stage designs are optimized starting from the corresponding group-sequential design as computed by the rpact package. order &lt;- 7L # data frame of initial designs tbl_designs &lt;- tibble( type = c(&quot;one-stage&quot;, &quot;group-sequential&quot;, &quot;two-stage&quot;), initial = list( OneStageDesign(200, 2.0), rpact_design(datadist, 0.4, 0.025, 0.8, TRUE, order), TwoStageDesign(rpact_design(datadist, 0.4, 0.025, 0.8, TRUE, order))) ) The order of integration is set to 7. 2.2.4 Optimization tbl_designs &lt;- tbl_designs %&gt;% mutate( optimal = purrr::map(initial, ~minimize( ess, subject_to( toer_cnstr, pow_cnstr ), initial_design = ., opts = opts)) ) 2.2.5 Test Cases To avoid improper solutions, it is first verified that the maximum number of iterations was not exceeded in any of the three cases. tbl_designs %&gt;% transmute( type, iterations = purrr::map_int(tbl_designs$optimal, ~.$nloptr_return$iterations) ) %&gt;% {print(.); .} %&gt;% {testthat::expect_true(all(.$iterations &lt; opts$maxeval))} ## # A tibble: 3 × 2 ## type iterations ## &lt;chr&gt; &lt;int&gt; ## 1 one-stage 24 ## 2 group-sequential 1349 ## 3 two-stage 3914 Next, the type one error rate and power constraints are verified for all three designs by simulation: tbl_designs %&gt;% transmute( type, toer = purrr::map(tbl_designs$optimal, ~sim_pr_reject(.[[1]], .0, datadist)$prob), power = purrr::map(tbl_designs$optimal, ~sim_pr_reject(.[[1]], .4, datadist)$prob) ) %&gt;% unnest(., cols = c(toer, power)) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$toer &lt;= alpha * (1 + tol))) testthat::expect_true(all(.$power &gt;= min_power * (1 - tol))) } ## # A tibble: 3 × 3 ## type toer power ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage 0.0251 0.799 ## 2 group-sequential 0.0250 0.800 ## 3 two-stage 0.0250 0.799 The \\(n_2\\) function of the optimal two-stage design is expected to be monotonously decreasing: testthat::expect_true( all(diff( # get optimal two-stage design n2 pivots tbl_designs %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% {.[[&quot;optimal&quot;]][[1]]$design@n2_pivots} ) &lt; 0) ) Since the degrees of freedom of the three design classes are ordered as ‘two-stage’ &gt; ‘group-sequential’ &gt; ‘one-stage’, the expected sample sizes (under the alternative) should be ordered in reverse (‘two-stage’ smallest). Additionally, expected sample sizes under both null and alternative are computed both via evaluate() and simulation-based. ess0 &lt;- ExpectedSampleSize(datadist, H_0) tbl_designs %&gt;% mutate( ess = map_dbl(optimal, ~evaluate(ess, .$design) ), ess_sim = map_dbl(optimal, ~sim_n(.$design, .4, datadist)$n ), ess0 = map_dbl(optimal, ~evaluate(ess0, .$design) ), ess0_sim = map_dbl(optimal, ~sim_n(.$design, .0, datadist)$n ) ) %&gt;% {print(.); .} %&gt;% { # sim/evaluate same under alternative? testthat::expect_equal(.$ess, .$ess_sim, tolerance = tol_n, scale = 1) # sim/evaluate same under null? testthat::expect_equal(.$ess0, .$ess0_sim, tolerance = tol_n, scale = 1) # monotonicity with respect to degrees of freedom testthat::expect_true(all(diff(.$ess) &lt; 0)) } ## # A tibble: 3 × 7 ## type initial optimal ess ess_sim ess0 ess0_sim ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage &lt;OnStgDsg&gt; &lt;adptrOpR [3]&gt; 98 98 98 98 ## 2 group-sequential &lt;GrpSqntD&gt; &lt;adptrOpR [3]&gt; 80.9 80.9 68.5 68.5 ## 3 two-stage &lt;TwStgDsg&gt; &lt;adptrOpR [3]&gt; 79.7 79.7 68.9 68.9 The expected sample size under the alternative must be lower or equal than the expected sample size of the initial rpact group-sequential design that is based on the inverse normal combination test. testthat::expect_lte( evaluate(ess, tbl_designs %&gt;% filter(type == &quot;group-sequential&quot;) %&gt;% pull(optimal) %&gt;% .[[1]] %&gt;% .$design ), evaluate(ess, tbl_designs %&gt;% filter(type == &quot;group-sequential&quot;) %&gt;% pull(initial) %&gt;% .[[1]] ) ) 2.3 Variant I-2: Minimizing Expected Sample Size under Null Hypothesis 2.3.1 Objective Expected sample size under the null hypothesis prior is minimized, i.e., ess0. 2.3.2 Constraints The constraints remain unchanged from the base case. 2.3.3 Initial Design Since optimization under the null favours an entirely different (monotonically increasing) sample size function, and thus also a different shape of the \\(c_2\\) function, the rpact initial design is a suboptimal starting point. Instead, we start with a constant \\(c_2\\) function by heuristically setting it to \\(2\\) on the continuation area. Also, optimizing under the null favours extremely conservative boundaries for early efficacy stopping and we thus impose as fairly liberal upper bound of \\(3\\) for early efficacy stopping. init_design_h0 &lt;- tbl_designs %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% pull(initial) %&gt;% .[[1]] init_design_h0@c2_pivots &lt;- rep(2, order) ub_design &lt;- TwoStageDesign( 3 * init_design_h0@n1, 2, 3, rep(300, order), rep(3.0, order) ) 2.3.4 Optimization The optimal two-stage design is computed. opt_h0 &lt;- minimize( ess0, subject_to( toer_cnstr, pow_cnstr ), initial_design = init_design_h0, upper_boundary_design = ub_design, opts = opts ) 2.3.5 Test Cases Make sure that the optimization algorithm converged within the set maximum number of iterations: opt_h0$nloptr_return$iterations %&gt;% {print(.); .} %&gt;% {testthat::expect_true(. &lt; opts$maxeval)} ## [1] 18708 The \\(n_2\\) function of the optimal two-stage design is expected to be monotonously increasing. expect_true( all(diff(opt_h0$design@n2_pivots) &gt; 0) ) Next, the type one error rate and power constraints are tested. tbl_performance &lt;- tibble( delta = c(.0, .4) ) %&gt;% mutate( power = map( delta, ~evaluate( Power(datadist, PointMassPrior(., 1)), opt_h0$design) ), power_sim = map( delta, ~sim_pr_reject(opt_h0$design, ., datadist)$prob), ess = map( delta, ~evaluate(ExpectedSampleSize( datadist, PointMassPrior(., 1) ), opt_h0$design) ), ess_sim = map( delta, ~sim_n(opt_h0$design, . ,datadist)$n ) ) %&gt;% unnest(., cols = c(power, power_sim, ess, ess_sim)) print(tbl_performance) ## # A tibble: 2 × 5 ## delta power power_sim ess ess_sim ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0.0250 0.0250 57.2 57.3 ## 2 0.4 0.802 0.802 118. 118. testthat::expect_lte( tbl_performance %&gt;% filter(delta == 0) %&gt;% pull(power_sim), alpha * (1 + tol) ) testthat::expect_gte( tbl_performance %&gt;% filter(delta == 0.4) %&gt;% pull(power_sim), min_power * (1 - tol) ) # make sure that evaluate() leads to same results testthat::expect_equal( tbl_performance$power, tbl_performance$power_sim, tol = tol, scale = 1 ) testthat::expect_equal( tbl_performance$ess, tbl_performance$ess_sim, tol = tol_n, scale = 1 ) The expected sample size under the null must be lower or equal than the expected sample size of the initial rpact group-sequential design. testthat::expect_gte( evaluate(ess0, tbl_designs %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% pull(initial) %&gt;% .[[1]] ), evaluate(ess0, opt_h0$design) ) 2.4 Variant I-3: Conditional Power Constraint 2.4.1 Objective Same as in I-1, i.e., expected sample size under the alternative point prior is minimized. 2.4.2 Constraints Besides the previous global type one error rate and power constraints, an additional constraint on conditional power is imposed. cp &lt;- ConditionalPower(datadist, prior) cp_cnstr &lt;- cp &gt;= .7 2.4.3 Initial Design The same initial (generic two-stage) design as in I-1 is used. 2.4.4 Optimization opt_cp &lt;- minimize( ess, subject_to( toer_cnstr, pow_cnstr, cp_cnstr # new constraint ), initial_design = tbl_designs %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% pull(initial) %&gt;% .[[1]], opts = opts ) 2.4.5 Test Cases Check if the optimization algorithm converged. opt_cp$nloptr_return$iterations %&gt;% {print(.); .} %&gt;% {testthat::expect_true(. &lt; opts$maxeval)} ## [1] 4136 Check constraints. tbl_performance &lt;- tibble( delta = c(.0, .4) ) %&gt;% mutate( power = map( delta, ~evaluate( Power(datadist, PointMassPrior(., 1)), opt_cp$design) ), power_sim = map( delta, ~sim_pr_reject(opt_cp$design, ., datadist)$prob), ess = map( delta, ~evaluate(ExpectedSampleSize( datadist, PointMassPrior(., 1) ), opt_cp$design) ), ess_sim = map( delta, ~sim_n(opt_cp$design, . ,datadist)$n ) ) %&gt;% unnest(., cols = c(power, power_sim, ess, ess_sim)) print(tbl_performance) ## # A tibble: 2 × 5 ## delta power power_sim ess ess_sim ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0.0250 0.0250 68.9 69.0 ## 2 0.4 0.799 0.799 79.8 79.8 testthat::expect_lte( tbl_performance %&gt;% filter(delta == 0) %&gt;% pull(power_sim), alpha * (1 + tol) ) testthat::expect_gte( tbl_performance %&gt;% filter(delta == 0.4) %&gt;% pull(power_sim), min_power * (1 - tol) ) # make sure that evaluate() leads to same results testthat::expect_equal( tbl_performance$power, tbl_performance$power_sim, tol = tol, scale = 1 ) testthat::expect_equal( tbl_performance$ess, tbl_performance$ess_sim, tol = tol_n, scale = 1 ) The conditional power constraint is evaluated and tested on a grid over the continuation region (both simulated an via numerical integration). tibble( x1 = seq(opt_cp$design@c1f, opt_cp$design@c1e, length.out = 25), cp = map_dbl(x1, ~evaluate(cp, opt_cp$design, .)), cp_sim = map_dbl(x1, function(x1) { x2 &lt;- simulate(datadist, 10^6, n2(opt_cp$design, x1), .4, 42) rej &lt;- ifelse(x2 &gt; c2(opt_cp$design, x1), 1, 0) return(mean(rej)) }) ) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$cp &gt;= 0.7 * (1 - tol))) testthat::expect_true(all(.$cp_sim &gt;= 0.7 * (1 - tol))) testthat::expect_true(all(abs(.$cp - .$cp_sim) &lt;= tol)) } ## # A tibble: 25 × 3 ## x1 cp cp_sim ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.810 0.701 0.701 ## 2 0.872 0.698 0.699 ## 3 0.934 0.701 0.701 ## 4 0.995 0.698 0.698 ## 5 1.06 0.700 0.700 ## 6 1.12 0.702 0.703 ## 7 1.18 0.699 0.699 ## 8 1.24 0.703 0.703 ## 9 1.30 0.713 0.713 ## 10 1.37 0.718 0.718 ## # ℹ 15 more rows Finally, the expected sample size under the alternative prior should be larger than in the case without the constraint I-1. testthat::expect_gte( evaluate(ess, opt_cp$design), evaluate( ess, tbl_designs %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% pull(optimal) %&gt;% .[[1]] %&gt;% .$design ) ) 2.5 Plot Two-Stage Designs The following figure shows the three optimal two-stage designs side by side. The effect of the conditional power constraint (CP not below 0.7) is clearly visible and the very different characteristics between optimizing under the null or the alternative are clearly visible. "],["scenarioII.html", "3 Scenario II: large effect, Gaussian prior 3.1 Details 3.2 Variant II-1: Minimizing Expected Sample Size under Point Prior 3.3 Variant II-2: Minimizing Expected Sample Size under Null Hypothesis 3.4 Variant II-3: Conditional Power Constraint 3.5 Plot Two-Stage Designs", " 3 Scenario II: large effect, Gaussian prior 3.1 Details In this scenario, we revisit the case from Scenario I, but are not assuming a point prior any more. Instead, a Gaussian prior with mean \\(\\vartheta = 0.4\\) and variance \\(\\tau^2 = 0.2^2\\) on the effect size is assumed, i.e.  \\(\\delta \\sim \\mathcal{N} (0.4, 0.2^2)\\). In order to fulfill regulatory considerations, the type one error rate is still protected under the point prior \\(\\delta = 0\\) at the level of significance \\(\\alpha = 0.025\\). The power constraint, however, needs to be modified. It is not senseful to compute the power as rejection probability under the full prior, because effect sizes less than a minimal clinically relevant effect do not show (sufficient) evidence againt the null hypothesis. Therefore, we assume a minimal clinically relevant effect size \\(\\delta = 0.0\\) and condition the prior on values \\(\\delta &gt; 0\\) to compute expected power. In the following, the expected power should be at least \\(0.8\\). # data distribution and priors datadist &lt;- Normal(two_armed = TRUE) H_0 &lt;- PointMassPrior(.0, 1) prior &lt;- ContinuousPrior(function(delta) dnorm(delta, mean = .4, sd = .2), support = c(-5, 5), tighten_support = TRUE) # define constraints on type one error rate and expected power alpha &lt;- 0.025 min_epower &lt;- 0.8 toer_cnstr &lt;- Power(datadist, H_0) &lt;= alpha epow_cnstr &lt;- Power(datadist, condition(prior, c(0.0, prior@support[2]))) &gt;= min_epower 3.2 Variant II-1: Minimizing Expected Sample Size under Point Prior 3.2.1 Objective Expected sample size under the full prior is minimized, i.e., \\(\\boldsymbol{E}\\big[n(\\mathcal{D})\\big]\\). ess &lt;- ExpectedSampleSize(datadist, prior) 3.2.2 Constraints No additional constraints are considered in this variant. 3.2.3 Initial Design For this example, the optimal one-stage, group-sequential, and generic two-stage designs are computed. While the initial design for the one-stage case is determined heuristically, both the group sequential and the generic two-stage designs are optimized starting from the a group-sequential design that is computed by the rpact package to fulfill the type one error rate constraint and that fulfills the power constraint at an effect size of \\(\\delta = 0.3\\). order &lt;- 5L # data frame of initial designs tbl_designs &lt;- tibble( type = c(&quot;one-stage&quot;, &quot;group-sequential&quot;, &quot;two-stage&quot;), initial = list( OneStageDesign(250, 2.0), rpact_design(datadist, 0.3, 0.025, 0.8, TRUE, order), TwoStageDesign(rpact_design(datadist, 0.3, 0.025, 0.8, TRUE, order))) ) The order of integration is set to 5. 3.2.4 Optimization For all these three initial designs, the resulting optimal designs are computed. tbl_designs &lt;- tbl_designs %&gt;% mutate( optimal = purrr::map(initial, ~minimize( ess, subject_to( toer_cnstr, epow_cnstr ), initial_design = ., opts = opts)) ) 3.2.5 Test Cases Firstly, it is checked that the maximum number of iterations was not reached in all these cases. tbl_designs %&gt;% transmute( type, iterations = purrr::map_int(tbl_designs$optimal, ~.$nloptr_return$iterations) ) %&gt;% {print(.); .} %&gt;% {testthat::expect_true(all(.$iterations &lt; opts$maxeval))} ## # A tibble: 3 × 2 ## type iterations ## &lt;chr&gt; &lt;int&gt; ## 1 one-stage 26 ## 2 group-sequential 710 ## 3 two-stage 2114 Since type one error rate is defined under the point effect size \\(\\delta=0\\), the type one error rate constraint can be tested for all three optimal designs. tbl_designs %&gt;% transmute( type, toer = purrr::map(tbl_designs$optimal, ~sim_pr_reject(.[[1]], .0, datadist)$prob) ) %&gt;% unnest(., cols = c(toer)) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$toer &lt;= alpha * (1 + tol))) } ## # A tibble: 3 × 2 ## type toer ## &lt;chr&gt; &lt;dbl&gt; ## 1 one-stage 0.0251 ## 2 group-sequential 0.0250 ## 3 two-stage 0.0249 Since the optimal two-stage design is more flexible than the optimal group-sequential design (constant \\(n_2\\) function) and this is more flexible than the optimal one-stage design (no second stage), the expected sample sizes under the prior should be ordered in the opposite way. Additionally, expected sample sizes under the null hypothesis are computed both via evaluate() and simulation-based. essh0 &lt;- ExpectedSampleSize(datadist, H_0) tbl_designs %&gt;% mutate( ess = map_dbl(optimal, ~evaluate(ess, .$design) ), essh0 = map_dbl(optimal, ~evaluate(essh0, .$design) ), essh0_sim = map_dbl(optimal, ~sim_n(.$design, .0, datadist)$n ) ) %&gt;% {print(.); .} %&gt;% { # sim/evaluate same under null? testthat::expect_equal(.$essh0, .$essh0_sim, tolerance = tol_n, scale = 1) # monotonicity with respect to degrees of freedom testthat::expect_true(all(diff(.$ess) &lt; 0)) } ## # A tibble: 3 × 6 ## type initial optimal ess essh0 essh0_sim ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage &lt;OnStgDsg&gt; &lt;adptrOpR [3]&gt; 165 165 165 ## 2 group-sequential &lt;GrpSqntD&gt; &lt;adptrOpR [3]&gt; 117. 115. 115. ## 3 two-stage &lt;TwStgDsg&gt; &lt;adptrOpR [3]&gt; 115. 119. 119. 3.3 Variant II-2: Minimizing Expected Sample Size under Null Hypothesis 3.3.1 Objective Expected sample size conditioned on negative effect sizes is minimized, i.e., ess_0 &lt;- ExpectedSampleSize(datadist, condition(prior, c(bounds(prior)[1], 0))) 3.3.2 Constraints No additional constraints besides type one error rate and expected power are considered in this variant. 3.3.3 Initial Design As in Variant I.2 another initial design is more appropriate for optimization under the null hypothesis. In this situation, one may expect a different (increasing) sample size function, and thus also a different shape of the \\(c_2\\) function. Therefore, the rpact initial design is a suboptimal starting point. Instead, we start with a constant \\(c_2\\) function by heuristically setting it to \\(2\\) on the continuation area. Since optimization under the null hypothesis favours extremely conservative boundaries for early efficacy stopping we impose as quite liberal upper bound of \\(3\\) for early efficacy stopping. init_design_h0 &lt;- tbl_designs %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% pull(initial) %&gt;% .[[1]] init_design_h0@c2_pivots &lt;- rep(2, order) ub_design &lt;- TwoStageDesign( 3 * init_design_h0@n1, 2, 3, rep(600, order), rep(3.0, order) ) 3.3.4 Optimization opt_neg &lt;- minimize( ess_0, subject_to( toer_cnstr, epow_cnstr ), initial_design = init_design_h0, upper_boundary_design = ub_design, opts = opts ) 3.3.5 Test Cases First of all, check if the optimization algorithm converged. To avoid improper solutions, it is first verified that the maximum number of iterations was not exceeded in any of the three cases. testthat::expect_true(opt_neg$nloptr_return$iterations &lt; opts$maxeval) print(opt_neg$nloptr_return$iterations) ## [1] 8239 Again, the type one error rate under the point null hypothesis \\(\\delta = 0\\) can be tested by simulation. tbl_toer &lt;- tibble( toer = evaluate(Power(datadist, H_0), opt_neg$design), toer_sim = sim_pr_reject(opt_neg$design, .0, datadist)$prob ) print(tbl_toer) ## # A tibble: 1 × 2 ## toer toer_sim ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.0249 0.0250 testthat::expect_true(tbl_toer$toer &lt;= alpha * (1 + tol)) testthat::expect_true(tbl_toer$toer_sim &lt;= alpha * (1 + tol)) Furthermore, the expected sample size under the prior conditioned on negative effect sizes (\\(\\delta \\leq 0\\)) should be lower for the optimal design derived in this variant than for the optimal design from Variant II.1 where expected sample size under the full prior was minimized. testthat::expect_lte( evaluate(ess_0, opt_neg$design), evaluate( ess_0, tbl_designs %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% pull(optimal) %&gt;% .[[1]] %&gt;% .$design ) ) 3.4 Variant II-3: Conditional Power Constraint 3.4.1 Objective As in Variant II-1, expected sample size under the full prior is minimized. 3.4.2 Constraints In addition to the constraints on type one error rate and expected power, a constraint on conditional power to be larger than \\(0.7\\) is included. cp &lt;- ConditionalPower(datadist, condition(prior, c(0, prior@support[2]))) cp_cnstr &lt;- cp &gt;= 0.7 3.4.3 Initial Design The previous initial design can still be applied. 3.4.4 Optimization opt_cp &lt;- minimize( ess, subject_to( toer_cnstr, epow_cnstr, cp_cnstr ), initial_design = tbl_designs$initial[[3]], opts = opts ) 3.4.5 Test Cases We start checking whether the maximum number of iterations was not reached. print(opt_cp$nloptr_return$iterations) ## [1] 1937 testthat::expect_true(opt_cp$nloptr_return$iterations &lt; opts$maxeval) The type one error rate is tested via simulation and compared to the value obtained by evaluate(). tbl_toer &lt;- tibble( toer = evaluate(Power(datadist, H_0), opt_cp$design), toer_sim = sim_pr_reject(opt_cp$design, .0, datadist)$prob ) print(tbl_toer) ## # A tibble: 1 × 2 ## toer toer_sim ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.0250 0.0250 testthat::expect_true(tbl_toer$toer &lt;= alpha * (1 + tol)) testthat::expect_true(tbl_toer$toer_sim &lt;= alpha * (1 + tol)) The conditional power is evaluated via numerical integration on several points inside the continuation region and it is tested whether the constraint is fulfilled on all these points. tibble( x1 = seq(opt_cp$design@c1f, opt_cp$design@c1e, length.out = 25), cp = map_dbl(x1, ~evaluate(cp, opt_cp$design, .)) ) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$cp &gt;= 0.7 * (1 - tol))) } ## # A tibble: 25 × 2 ## x1 cp ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.674 0.698 ## 2 0.747 0.700 ## 3 0.819 0.700 ## 4 0.891 0.699 ## 5 0.963 0.698 ## 6 1.03 0.698 ## 7 1.11 0.701 ## 8 1.18 0.705 ## 9 1.25 0.709 ## 10 1.32 0.715 ## # ℹ 15 more rows Due to the additional constraint in comparison to Variant II.1, Variant II.3 should show a larger expected sample size under the prior than Variant II.1 testthat::expect_gte( evaluate(ess, opt_cp$design), evaluate( ess, tbl_designs %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% pull(optimal) %&gt;% .[[1]] %&gt;% .$design ) ) 3.5 Plot Two-Stage Designs The optimal two-stage designs stemming from the different variants are plotted together. "],["scenarioIII.html", "4 Scenario III: large effect, uniform prior 4.1 Details 4.2 Variant III.1: Convergence under prior concentration", " 4 Scenario III: large effect, uniform prior 4.1 Details This scenario covers a similar setting as Scenario I. The purpose is to asses whether placing uniform priors with decreasing width of support centered at \\(\\delta=0.4\\) leads to a sequence of optimal designs which converges towards the solution in variant I-1. The trial is still considered to be two-armed with normally distribtuted outcomes and the type one error rate under the null hypothesis \\(\\mathcal{H}_0:\\delta \\leq 0\\) is to be protected at \\(\\alpha = 0.025\\). datadist &lt;- Normal(two_armed = TRUE) H_0 &lt;- PointMassPrior(.0, 1) alpha &lt;- 0.025 toer_cnstr &lt;- Power(datadist, H_0) &lt;= alpha In this scenario we consider a sequence of uniform distributions \\(\\delta\\sim\\operatorname{Unif}(0.4 - \\Delta_i, 0.4 + \\Delta_i)\\) around \\(0.4\\) with \\(\\Delta_i=(3 - i)/10\\) for \\(i=0\\ldots 3\\). I.e., for \\(\\Delta_3=0\\) reduces to PointMassPrior on \\(\\delta=0.4\\). prior &lt;- function(delta) { if (delta == 0) return(PointMassPrior(.4, 1.0)) a &lt;- .4 - delta; b &lt;- .4 + delta ContinuousPrior(function(x) dunif(x, a, b), support = c(a, b)) } Across all variants in this scenario, the expected power under the respective prior conditioned on \\(\\delta &gt; 0\\) must be at least \\(0.8\\). I.e., throughout this scenario, we always use the following constraint on expected power. ep_cnstr &lt;- function(delta) { prior &lt;- prior(delta) cnd_prior &lt;- condition(prior, c(0, bounds(prior)[2])) return( Power(datadist, cnd_prior) &gt;= 0.8 ) } 4.2 Variant III.1: Convergence under prior concentration The goal of this variant is to make sure that the optimal solution converges as the prior is more and more concentrated at a point mass. 4.2.1 Objective Expected sample size under the respective prior is minimized, i.e., \\(\\boldsymbol{E}\\big[n(\\mathcal{D})\\big]\\). objective &lt;- function(delta) { ExpectedSampleSize(datadist, prior(delta)) } 4.2.2 Constraints The constraints have already been described under details. 4.2.3 Optimization problem The optimization problem depending on \\(\\Delta_i\\) is defined below. The default optimization parameters, 5 pivot points, and a fixed initial design are used. The initial design is chosen such that the error constraints are fulfilled. Early stopping for futility is applied if the effect shows in the opponent direction to the alternative, i.e. \\(c_1^f=0\\). \\(c_2\\) is chosen close to and \\(c_1^e\\) a little larger than the \\(1-\\alpha\\)-quantile of the standard normal distribution. The sample sizes are selected to fulfill the error constraints. init &lt;- TwoStageDesign( n1 = 150, c1f = 0, c1e = 2.3, n2 = 125.0, c2 = 2.0, order = 5 ) optimal_design &lt;- function(delta) { minimize( objective(delta), subject_to( toer_cnstr, ep_cnstr(delta) ), initial_design = init ) } # compute the sequence of optimal designs deltas &lt;- 3:0/10 results &lt;- lapply(deltas, optimal_design) 4.2.4 Test cases Check that iteration limit was not exceeded in any case. iters &lt;- sapply(results, function(x) x$nloptr_return$iterations) print(iters) ## [1] 2380 1993 2685 2789 testthat::expect_true(all(iters &lt;= opts$maxeval)) Check type one error rate control by simulation and by calling evaluate(). df_toer &lt;- tibble( delta = deltas, toer = sapply(results, function(x) evaluate(Power(datadist, H_0), x$design)), toer_sim = sapply(results, function(x) sim_pr_reject(x$design, .0, datadist)$prob) ) testthat::expect_true(all(df_toer$toer &lt;= alpha * (1 + tol))) testthat::expect_true(all(df_toer$toer_sim &lt;= alpha * (1 + tol))) print(df_toer) ## # A tibble: 4 × 3 ## delta toer toer_sim ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.3 0.0250 0.0250 ## 2 0.2 0.0250 0.0250 ## 3 0.1 0.0250 0.0250 ## 4 0 0.0250 0.0250 Check that expected sample size decreases with decreasing prior variance. testthat::expect_gte( evaluate(objective(deltas[1]), results[[1]]$design), evaluate(objective(deltas[2]), results[[2]]$design) ) testthat::expect_gte( evaluate(objective(deltas[2]), results[[2]]$design), evaluate(objective(deltas[3]), results[[3]]$design) ) testthat::expect_gte( evaluate(objective(deltas[3]), results[[3]]$design), evaluate(objective(deltas[4]), results[[4]]$design) ) 4.2.5 Plot designs Finally, we plot the designs and assess for convergence. "],["scenarioIV.html", "5 Scenario IV: smaller effect, point prior 5.1 Details 5.2 Variant IV-1: Minimizing Expected Sample Size under Point Prior 5.3 Variant IV-2: Increase Power 5.4 Variant IV-3: Increase Type One Error rate 5.5 Plot Two-Stage Designs", " 5 Scenario IV: smaller effect, point prior 5.1 Details In this scenario, we return to point priors as investigated in Scenario I. The main goal is to validate adoptr’s sensitivity with regard to the assumed effect size and the constraints on power and type one error rate. Therefore, we still assume a two-armed trial with normally distributed outcomes. The assumed effect size under the alternative is \\(\\delta = 0.2\\) in this setting. Type one error rate is protected at \\(2.5\\%\\) and the power should be at least \\(80\\%\\). We will vary these values in the variants IV.2 and IV.3 # data distribution and hypotheses datadist &lt;- Normal(two_armed = TRUE) H_0 &lt;- PointMassPrior(.0, 1) prior &lt;- PointMassPrior(.2, 1) # constraints alpha &lt;- 0.025 min_power &lt;- 0.8 toer_cnstr &lt;- Power(datadist, H_0) &lt;= alpha pow_cnstr &lt;- Power(datadist, prior) &gt;= min_power 5.2 Variant IV-1: Minimizing Expected Sample Size under Point Prior 5.2.1 Objective Expected sample size under the alternative point prior \\(\\delta = 0.2\\) is minimized. ess &lt;- ExpectedSampleSize(datadist, prior) 5.2.2 Constraints No additional constraints are considered in this variant. 5.2.3 Initial Design For this example, the optimal one-stage, group-sequential, and generic two-stage designs are computed. The initial design that is used as starting value of optimization is defined as a group-sequential design by the package rpact that fulfills type one error rate and power constraints in the case of group-sequential and two-stage design. The initial one-stage design is chosen heuristically. The order of integration is set to \\(5\\). order &lt;- 5L tbl_designs &lt;- tibble( type = c(&quot;one-stage&quot;, &quot;group-sequential&quot;, &quot;two-stage&quot;), initial = list( OneStageDesign(500, 2.0), rpact_design(datadist, 0.2, 0.025, 0.8, TRUE, order), TwoStageDesign(rpact_design(datadist, 0.2, 0.025, 0.8, TRUE, order))) ) 5.2.4 Optimization tbl_designs &lt;- tbl_designs %&gt;% mutate( optimal = purrr::map(initial, ~minimize( ess, subject_to( toer_cnstr, pow_cnstr ), initial_design = ., opts = opts)) ) 5.2.5 Test Cases Firstly, it is checked whether the maximum number of iterations was not exceeded in all three cases. tbl_designs %&gt;% transmute( type, iterations = purrr::map_int(tbl_designs$optimal, ~.$nloptr_return$iterations) ) %&gt;% {print(.); .} %&gt;% {testthat::expect_true(all(.$iterations &lt; opts$maxeval))} ## # A tibble: 3 × 2 ## type iterations ## &lt;chr&gt; &lt;int&gt; ## 1 one-stage 20 ## 2 group-sequential 739 ## 3 two-stage 2196 Now, the constraints on type one error rate and power are tested via simulation. tbl_designs %&gt;% transmute( type, toer = purrr::map(tbl_designs$optimal, ~sim_pr_reject(.[[1]], .0, datadist)$prob), power = purrr::map(tbl_designs$optimal, ~sim_pr_reject(.[[1]], .2, datadist)$prob) ) %&gt;% unnest(., cols = c(toer, power)) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$toer &lt;= alpha * (1 + tol))) testthat::expect_true(all(.$power &gt;= min_power * (1 - tol))) } ## # A tibble: 3 × 3 ## type toer power ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage 0.0251 0.799 ## 2 group-sequential 0.0250 0.800 ## 3 two-stage 0.0250 0.800 Due to increasing degrees of freedom, the expected sample sizes under the alternative should be ordered as ‘one-stage &gt; group-sequential &gt; two-stage’. They are evaluated by simulation as well as by evaluate(). tbl_designs %&gt;% mutate( ess = map_dbl(optimal, ~evaluate(ess, .$design) ), ess_sim = map_dbl(optimal, ~sim_n(.$design, .2, datadist)$n ) ) %&gt;% {print(.); .} %&gt;% { # sim/evaluate same under alternative? testthat::expect_equal(.$ess, .$ess_sim, tolerance = tol_n, scale = 1) # monotonicity with respect to degrees of freedom testthat::expect_true(all(diff(.$ess) &lt; 0)) } ## # A tibble: 3 × 5 ## type initial optimal ess ess_sim ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage &lt;OnStgDsg&gt; &lt;adptrOpR [3]&gt; 392 392 ## 2 group-sequential &lt;GrpSqntD&gt; &lt;adptrOpR [3]&gt; 324. 323. ## 3 two-stage &lt;TwStgDsg&gt; &lt;adptrOpR [3]&gt; 320. 319. Furthermore, the expected sample size under the alternative of the optimal group-sequential design should be lower than for the group-sequential design by rpact that is based on the inverse normal combination test. tbl_designs %&gt;% filter(type == &quot;group-sequential&quot;) %&gt;% { expect_lte( evaluate(ess, {.[[&quot;optimal&quot;]][[1]]$design}), evaluate(ess, {.[[&quot;initial&quot;]][[1]]}) ) } Finally, the \\(n_2\\) function of the optimal two-stage design is expected to be monotonously decreasing: expect_true( all(diff( # get optimal two-stage design n2 pivots tbl_designs %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% {.[[&quot;optimal&quot;]][[1]]$design@n2_pivots} ) &lt; 0) ) 5.3 Variant IV-2: Increase Power 5.3.1 Objective The objective remains expected sample size under the alternative \\(\\delta = 0.2\\). 5.3.2 Constraints The minimal required power is increased to \\(90\\%\\). min_power_2 &lt;- 0.9 pow_cnstr_2 &lt;- Power(datadist, prior) &gt;= min_power_2 5.3.3 Initial Design For both flavours with two stages (group-sequential, generic two-stage) the initial design is created by rpact to fulfill the error rate constraints. tbl_designs_9 &lt;- tibble( type = c(&quot;one-stage&quot;, &quot;group-sequential&quot;, &quot;two-stage&quot;), initial = list( OneStageDesign(500, 2.0), rpact_design(datadist, 0.2, 0.025, 0.9, TRUE, order), TwoStageDesign(rpact_design(datadist, 0.2, 0.025, 0.9, TRUE, order))) ) 5.3.4 Optimization tbl_designs_9 &lt;- tbl_designs_9 %&gt;% mutate( optimal = purrr::map(initial, ~minimize( ess, subject_to( toer_cnstr, pow_cnstr_2 ), initial_design = ., opts = opts)) ) 5.3.5 Test Cases We start checking if the maximum number of iterations was not exceeded in all three cases. tbl_designs_9 %&gt;% transmute( type, iterations = purrr::map_int(tbl_designs_9$optimal, ~.$nloptr_return$iterations) ) %&gt;% {print(.); .} %&gt;% {testthat::expect_true(all(.$iterations &lt; opts$maxeval))} ## # A tibble: 3 × 2 ## type iterations ## &lt;chr&gt; &lt;int&gt; ## 1 one-stage 30 ## 2 group-sequential 1172 ## 3 two-stage 3025 The type one error rate and power constraints are evaluated by simulation. tbl_designs_9 %&gt;% transmute( type, toer = purrr::map(tbl_designs_9$optimal, ~sim_pr_reject(.[[1]], .0, datadist)$prob), power = purrr::map(tbl_designs_9$optimal, ~sim_pr_reject(.[[1]], .2, datadist)$prob) ) %&gt;% unnest(., cols = c(toer, power)) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$toer &lt;= alpha * (1 + tol))) testthat::expect_true(all(.$power &gt;= min_power_2 * (1 - tol))) } ## # A tibble: 3 × 3 ## type toer power ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage 0.0251 0.900 ## 2 group-sequential 0.0249 0.900 ## 3 two-stage 0.0250 0.900 Due to increasing degrees of freedom, the expected sample sizes under the alternative should be ordered as ‘one-stage &gt; group-sequential &gt; two-stage’. This is tested by simulation as well as by evaluate(). tbl_designs_9 %&gt;% mutate( ess = map_dbl(optimal, ~evaluate(ess, .$design) ), ess_sim = map_dbl(optimal, ~sim_n(.$design, .2, datadist)$n ) ) %&gt;% {print(.); .} %&gt;% { # sim/evaluate same under alternative? testthat::expect_equal(.$ess, .$ess_sim, tolerance = tol_n, scale = 1) # monotonicity with respect to degrees of freedom testthat::expect_true(all(diff(.$ess) &lt; 0)) testthat::expect_true(all(diff(.$ess_sim) &lt; 0))} ## # A tibble: 3 × 5 ## type initial optimal ess ess_sim ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage &lt;OnStgDsg&gt; &lt;adptrOpR [3]&gt; 525 525 ## 2 group-sequential &lt;GrpSqntD&gt; &lt;adptrOpR [3]&gt; 405. 405. ## 3 two-stage &lt;TwStgDsg&gt; &lt;adptrOpR [3]&gt; 397. 397. Comparing with the inverse-normal based group-sequential design created by rpact, the optimal group-sequential design should show a lower expected sample size under the point alternative. tbl_designs_9 %&gt;% filter(type == &quot;group-sequential&quot;) %&gt;% { expect_lte( evaluate(ess, {.[[&quot;optimal&quot;]][[1]]$design}), evaluate(ess, {.[[&quot;initial&quot;]][[1]]}) ) } Since a point prior is regarded, the \\(n_2\\) function of the optimal two-stage design is expected to be monotonously decreasing: expect_true( all(diff( # get optimal two-stage design n2 pivots tbl_designs_9 %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% {.[[&quot;optimal&quot;]][[1]]$design@n2_pivots} ) &lt; 0) ) 5.4 Variant IV-3: Increase Type One Error rate 5.4.1 Objective As in variants IV.1 and IV-2, expected sample size under the point alternative is minimized. 5.4.2 Constraints While the power is still lower bounded by \\(90\\%\\) as in variant II, the maximal type one error rate is increased to \\(5\\%\\). alpha_2 &lt;- .05 toer_cnstr_2 &lt;- Power(datadist, H_0) &lt;= alpha_2 5.4.3 Initial Design Again, a design computed by means of the package rpact to fulfill the updated error rate constraints is applied as initial design for the optimal group-sequential and generic two-stage designs. tbl_designs_5 &lt;- tibble( type = c(&quot;one-stage&quot;, &quot;group-sequential&quot;, &quot;two-stage&quot;), initial = list( OneStageDesign(500, 2.0), rpact_design(datadist, 0.2, 0.05, 0.9, TRUE, order), TwoStageDesign(rpact_design(datadist, 0.2, 0.05, 0.9, TRUE, order))) ) 5.4.4 Optimization tbl_designs_5 &lt;- tbl_designs_5 %&gt;% mutate( optimal = purrr::map(initial, ~minimize( ess, subject_to( toer_cnstr_2, pow_cnstr_2 ), initial_design = ., opts = opts)) ) 5.4.5 Test Cases The convergence of the optimization algorithm is tested by checking if the maximum number of iterations was not exceeded. tbl_designs_5 %&gt;% transmute( type, iterations = purrr::map_int(tbl_designs_5$optimal, ~.$nloptr_return$iterations) ) %&gt;% {print(.); .} %&gt;% {testthat::expect_true(all(.$iterations &lt; opts$maxeval))} ## # A tibble: 3 × 2 ## type iterations ## &lt;chr&gt; &lt;int&gt; ## 1 one-stage 27 ## 2 group-sequential 1183 ## 3 two-stage 1925 By simulation, the constraints on the error rates (type one error and power) are tested. tbl_designs_5 %&gt;% transmute( type, toer = purrr::map(tbl_designs_5$optimal, ~sim_pr_reject(.[[1]], .0, datadist)$prob), power = purrr::map(tbl_designs_5$optimal, ~sim_pr_reject(.[[1]], .2, datadist)$prob) ) %&gt;% unnest(., cols = c(toer, power)) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$toer &lt;= alpha_2 * (1 + tol))) testthat::expect_true(all(.$power &gt;= min_power_2 * (1 - tol))) } ## # A tibble: 3 × 3 ## type toer power ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage 0.0502 0.900 ## 2 group-sequential 0.0500 0.900 ## 3 two-stage 0.0502 0.900 Due to increasing degrees of freedom, the expected sample sizes under the alternative should be ordered as ‘one-stage &gt; group-sequential &gt; two-stage’. They are tested by simulation as well as by calling evaluate(). tbl_designs_5 %&gt;% mutate( ess = map_dbl(optimal, ~evaluate(ess, .$design) ), ess_sim = map_dbl(optimal, ~sim_n(.$design, .2, datadist)$n ) ) %&gt;% {print(.); .} %&gt;% { # sim/evaluate same under alternative? testthat::expect_equal(.$ess, .$ess_sim, tolerance = tol_n, scale = 1) # monotonicity with respect to degrees of freedom testthat::expect_true(all(diff(.$ess) &lt; 0)) } ## # A tibble: 3 × 5 ## type initial optimal ess ess_sim ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage &lt;OnStgDsg&gt; &lt;adptrOpR [3]&gt; 428 428 ## 2 group-sequential &lt;GrpSqntD&gt; &lt;adptrOpR [3]&gt; 325. 325. ## 3 two-stage &lt;TwStgDsg&gt; &lt;adptrOpR [3]&gt; 319. 319. The expected sample size under the alternative that was used as objective criterion of the optimal group-sequential design should be lower than for the group-sequential design by rpact that is based on the inverse normal combination test. tbl_designs_5 %&gt;% filter(type == &quot;group-sequential&quot;) %&gt;% { expect_lte( evaluate(ess, {.[[&quot;optimal&quot;]][[1]]$design}), evaluate(ess, {.[[&quot;initial&quot;]][[1]]}) ) } Also in this variant, the \\(n_2\\) function of the optimal two-stage design is expected to be monotonously decreasing: expect_true( all(diff( # get optimal two-stage design n2 pivots tbl_designs_5 %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% {.[[&quot;optimal&quot;]][[1]]$design@n2_pivots} ) &lt; 0) ) 5.5 Plot Two-Stage Designs The optimal two-stage designs stemming from the three different variants are plotted together. "],["scenarioV.html", "6 Scenario V: single-arm design, medium effect size 6.1 Details 6.2 Variant V-1, sensitivity to integration order 6.3 Variant V-2, utility maximization 6.4 Variant V-3, n1-penalty 6.5 Variant V-4, n2-penalty", " 6 Scenario V: single-arm design, medium effect size 6.1 Details In this scenario, again a point prior is analyzed. The null hypothesis is \\(\\delta \\leq 0\\) and we assume an alternative effect size of \\(\\delta = 0.3\\). Type one error rate should be protected at 2.5% and the design’s power should be at least 80%. Differently than in the previous scenarios, we are assuming a single-arm design throughout this scenario. # data distribution and hypotheses datadist &lt;- Normal(two_armed = FALSE) H_0 &lt;- PointMassPrior(.0, 1) prior &lt;- PointMassPrior(.3, 1) # define constraints alpha &lt;- 0.025 min_power &lt;- 0.8 toer_cnstr &lt;- Power(datadist, H_0) &lt;= alpha pow_cnstr &lt;- Power(datadist, prior) &gt;= min_power 6.2 Variant V-1, sensitivity to integration order In this variant, the sensitivity of the optimization with respect to the integration order is investigated. We apply three different integration orders: 5, 8, and 11. 6.2.1 Objective Expected sample size under the alternative point mass prior \\(\\delta = 0.3\\) is minimized. ess &lt;- ExpectedSampleSize(datadist, prior) 6.2.2 Constraints No additional constraints are considered in this variant. 6.2.3 Initial Design In order to vary the initial design, rpact is not used in this variant. Instead, the following heuristical considerations are made. A fixed design for these parameters would require 176 subjects per group. We use the half of this as initial values for the sample sizes. The initial stop for futility is at \\(c_1^f=0\\), i.e., if the effect shows in the opponent direction to the alternative. The starting values for the efficacy stop and for \\(c_2\\) is the \\(1-\\alpha\\)- quantile of the normal distribution. init_design &lt;- function(order) { TwoStageDesign( n1 = ceiling(pwr::pwr.t.test(d = .3, sig.level = .025, power = .8, alternative = &quot;greater&quot;)$n) / 2, c1f = 0, c1e = qnorm( 1 - 0.025), n2 = ceiling(pwr::pwr.t.test(d = .3, sig.level = .025, power = .8, alternative = &quot;greater&quot;)$n) / 2, c2 = qnorm(1 - 0.025), order = order ) } 6.2.4 Optimization The optimal design is computed for three different integration orders: 5, 8, and 11. opt_design &lt;- function(order) { minimize( ess, subject_to( toer_cnstr, pow_cnstr ), initial_design = init_design(order), upper_boundary_design = TwoStageDesign(200, 2, 4, 200, 3, order), opts = opts ) } opt &lt;- tibble( order = c(5, 8, 11), design = lapply(c(5, 8, 11), function(x) opt_design(x)) ) 6.2.5 Test cases Check if the optimization algorithm converged in all cases. opt %&gt;% transmute( order, iterations = purrr::map_int(opt$design, ~.$nloptr_return$iterations) ) %&gt;% {print(.); .} %&gt;% {testthat::expect_true(all(.$iterations &lt; opts$maxeval))} ## # A tibble: 3 × 2 ## order iterations ## &lt;dbl&gt; &lt;int&gt; ## 1 5 2372 ## 2 8 5378 ## 3 11 10689 Test the constraints on type one error rate and power by simulation and compare the results to the outcome of evaluate(). opt %&gt;% transmute( order, toer = map_dbl(design, ~evaluate(Power(datadist, PointMassPrior(.0, 1)), .$design) ), toer_sim = map_dbl(opt$design, ~sim_pr_reject(.[[1]], .0, datadist)$prob), power = map_dbl(design, ~evaluate(Power(datadist, PointMassPrior(.3, 1)), .$design) ), power_sim = map_dbl(opt$design, ~sim_pr_reject(.[[1]], .3, datadist)$prob), ess = map_dbl(design, ~evaluate(ess, .$design) ), ess_sim = map_dbl(opt$design, ~sim_n(.[[1]], .3, datadist)$n) ) %&gt;% unnest(., cols = c(toer, toer_sim, power, power_sim)) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$toer &lt;= alpha * (1 + tol))) testthat::expect_true(all(.$toer_sim &lt;= alpha * (1 + tol))) testthat::expect_true(all(.$power &gt;= min_power * (1 - tol))) testthat::expect_true(all(.$power_sim &gt;= min_power * (1 - tol))) } ## # A tibble: 3 × 7 ## order toer toer_sim power power_sim ess ess_sim ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5 0.0250 0.0250 0.799 0.800 71.0 71.0 ## 2 8 0.0250 0.0250 0.800 0.800 71.0 71.0 ## 3 11 0.0250 0.0250 0.800 0.800 71.0 71.0 6.3 Variant V-2, utility maximization 6.3.1 Objective In this variant, a utility function consisting of expected sample size and power is minimized. The parameter \\(\\lambda\\) that is describing the ratio between expected sample size and power is varied. pow &lt;- Power(datadist, prior) ess &lt;- ExpectedSampleSize(datadist, prior) obj &lt;- function(lambda) { composite({ess - lambda * pow}) } 6.3.2 Constraints The type one error rate is controlled at 0.025 on the boundary of the null hypothesis. Hence, the previous inequality can still be used. There is no constraint on power any more because power is part of the objective utility function. 6.3.3 Initial Design The previous initial design with order \\(5\\) is applied. 6.3.4 Optimization The optimal design is computed for two values of \\(\\lambda\\): 100 and 200. opt_utility &lt;- tibble( lambda = c(100, 200) ) %&gt;% mutate( design = purrr::map(lambda, ~minimize( obj(.), subject_to( toer_cnstr ), initial_design = init_design(5), opts = opts)) ) 6.3.5 Test cases Firstly, it is checked whether the maximum number of iterations was not exceeded in both flavours. opt_utility %&gt;% transmute( lambda, iterations = purrr::map_int(opt_utility$design, ~.$nloptr_return$iterations) ) %&gt;% {print(.); .} %&gt;% {testthat::expect_true(all(.$iterations &lt; opts$maxeval))} ## # A tibble: 2 × 2 ## lambda iterations ## &lt;dbl&gt; &lt;int&gt; ## 1 100 3338 ## 2 200 3154 Type one error rate control is tested for both designs by simulation and by adoptr’s function evaluate. In addition, it is tested if the design with larger \\(\\lambda\\) (i.e., stronger focus on power), shows the larger overall power. opt_utility %&gt;% transmute( lambda, toer = map_dbl(design, ~evaluate(Power(datadist, PointMassPrior(.0, 1)), .$design) ), toer_sim = purrr::map(opt_utility$design, ~sim_pr_reject(.[[1]], .0, datadist)$prob), power = map_dbl(design, ~evaluate(Power(datadist, PointMassPrior(.3, 1)), .$design) ), power_sim = purrr::map(opt_utility$design, ~sim_pr_reject(.[[1]], .3, datadist)$prob) ) %&gt;% unnest(., c(toer, toer_sim, power, power_sim)) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$toer &lt;= alpha * (1 + tol))) testthat::expect_true(all(.$toer_sim &lt;= alpha * (1 + tol))) testthat::expect_lte(.$power[1], .$power[2]) } ## # A tibble: 2 × 5 ## lambda toer toer_sim power power_sim ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 100 0.0250 0.0250 0.519 0.520 ## 2 200 0.0251 0.0250 0.897 0.897 Finally, the three designs computed so far are plotted together to allow comparison. 6.4 Variant V-3, n1-penalty In this variant, the influence of the regularization term N1() is investigated. 6.4.1 Objective In order to analyse the influence of N1(), a mixed criterion consisting of expected sample size under the point prior and \\(N1()\\) is minimized. N1 &lt;- N1() obj_n1 &lt;- function(lambda) { composite({ess + lambda * N1}) } 6.4.2 Constraints The inequalities from variant V.1 can still be used. 6.4.3 Initial Design The previous initial design with order \\(5\\) is applied. This variant requires an upper bound on \\(c_2\\). Otherwise, very large values for \\(c_2\\) and large \\(n_2\\)-values would allow appear to reduce \\(n_1\\). ub_design &lt;- get_upper_boundary_design(init_design(5)) ub_design@c2_pivots &lt;- rep(3, 5) 6.4.4 Optimization The optimal design is computed for two values of \\(\\lambda\\): 0.05 and 0.2. opt_n1 &lt;- tibble( lambda = c(0.05, 0.2) ) %&gt;% mutate( design = purrr::map(lambda, ~minimize( obj_n1(.), subject_to( toer_cnstr, pow_cnstr ), initial_design = init_design(5), upper_boundary_design = ub_design, opts = opts)) ) 6.4.5 Test cases We start testing if the optimization algorithm converged in both cases opt_n1 %&gt;% transmute( lambda, iterations = purrr::map_int(opt_n1$design, ~.$nloptr_return$iterations) ) %&gt;% {print(.); .} %&gt;% {testthat::expect_true(all(.$iterations &lt; opts$maxeval))} ## # A tibble: 2 × 2 ## lambda iterations ## &lt;dbl&gt; &lt;int&gt; ## 1 0.05 3133 ## 2 0.2 2921 Next, the error rate constraints on type one error rate and power are both tested by simulation and by the evaluate-call. opt_n1 %&gt;% transmute( lambda, toer = map_dbl(design, ~evaluate(Power(datadist, PointMassPrior(.0, 1)), .$design) ), toer_sim = purrr::map(opt_n1$design, ~sim_pr_reject(.[[1]], .0, datadist)$prob), power = map_dbl(design, ~evaluate(Power(datadist, PointMassPrior(.3, 1)), .$design) ), power_sim = purrr::map(opt_n1$design, ~sim_pr_reject(.[[1]], .3, datadist)$prob) ) %&gt;% unnest(., cols = c(toer, toer_sim, power, power_sim)) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$toer &lt;= alpha * (1 + tol))) testthat::expect_true(all(.$toer_sim &lt;= alpha * (1 + tol))) testthat::expect_true(all(.$power &gt;= min_power * (1 - tol))) testthat::expect_true(all(.$power_sim &gt;= min_power * (1 - tol))) } ## # A tibble: 2 × 5 ## lambda toer toer_sim power power_sim ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.05 0.0250 0.0250 0.801 0.801 ## 2 0.2 0.0250 0.0250 0.800 0.800 Since \\(n_1\\) is penalized in both flavours that are computed in this variant, we expect a lower \\(n_1\\) value as larger \\(\\lambda\\). Furthermore, \\(n_1\\) should be lower in both cases than in the unpenalized situation regarded in variant V.1. Finally, these three designs are plotted together to allow graphical comparison. ## # A tibble: 3 × 3 ## type design n_1 ## &lt;chr&gt; &lt;list&gt; &lt;dbl&gt; ## 1 No Penalization on n_1 &lt;TwStgDsg&gt; 50 ## 2 Penalization on n_1 with lambda = 0.05 &lt;TwStgDsg&gt; 48 ## 3 Penalization on n_1 with lambda = 0.2 &lt;TwStgDsg&gt; 41 6.5 Variant V-4, n2-penalty Here, we alter the situation from variant V.3 by not penalizing \\(n_1\\), but the average stage-two sample size \\(n_2\\). This can be done by means of the function AverageN2(). 6.5.1 Objective As in variant V.3, a mixed criterion is minimized. Here, it consists of expected sample size under the point prior and the average of \\(n_2\\). avn2 &lt;- AverageN2() obj_n2 &lt;- function(lambda) { composite({ess + lambda * avn2}) } 6.5.2 Constraints The inequalities from variant V.1 can still be used. 6.5.3 Initial Design The previous initial design with order \\(8\\) is applied. However, this case requires the definition of an upper-bound for \\(c_2\\). Otherwise, very small \\(n_2\\)-values and very large \\(c_2\\)-values would appear close to the early-futility-stop boundary in order to decrease the average \\(n_2\\). ub_design &lt;- get_upper_boundary_design(init_design(8)) ub_design@c2_pivots &lt;- rep(2.5, 8) 6.5.4 Optimization The optimal design is computed for two values of \\(\\lambda\\): 0.01 and 0.1. opt_n2 &lt;- tibble( lambda = c(0.01, 0.1) ) %&gt;% mutate( design = purrr::map(lambda, ~minimize( obj_n2(.), subject_to( toer_cnstr, pow_cnstr ), initial_design = init_design(8), upper_boundary_design = ub_design, opts = opts)) ) 6.5.5 Test cases As first step, we check if the maximum number of iterations was not exceeded in both cases. opt_n2 %&gt;% transmute( lambda, iterations = purrr::map_int(opt_n2$design, ~.$nloptr_return$iterations) ) %&gt;% {print(.); .} %&gt;% {testthat::expect_true(all(.$iterations &lt; opts$maxeval))} ## # A tibble: 2 × 2 ## lambda iterations ## &lt;dbl&gt; &lt;int&gt; ## 1 0.01 18398 ## 2 0.1 11123 As second step, the type one error rate and power restrictions are tested by simulation and by calling evaluate. opt_n2 %&gt;% transmute( lambda, toer = map_dbl(design, ~evaluate(Power(datadist, PointMassPrior(.0, 1)), .$design) ), toer_sim = purrr::map(opt_n2$design, ~sim_pr_reject(.[[1]], .0, datadist)$prob), power = map_dbl(design, ~evaluate(Power(datadist, PointMassPrior(.3, 1)), .$design) ), power_sim = purrr::map(opt_n2$design, ~sim_pr_reject(.[[1]], .3, datadist)$prob) ) %&gt;% unnest(., c(toer, toer_sim, power, power_sim)) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$toer &lt;= alpha * (1 + tol))) testthat::expect_true(all(.$toer_sim &lt;= alpha * (1 + tol))) testthat::expect_true(all(.$power &gt;= min_power * (1 - tol))) testthat::expect_true(all(.$power_sim &gt;= min_power * (1 - tol))) } ## # A tibble: 2 × 5 ## lambda toer toer_sim power power_sim ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.01 0.0250 0.0249 0.802 0.802 ## 2 0.1 0.0250 0.0250 0.801 0.801 Due to increasing penalization, it is assumed that the optimal design computed in variant V.1 (no penalization) shows a larger average \\(n_2\\) than the optimal penalized design with \\(\\lambda = 0.01\\) and this shows a larger average \\(n_2\\) than the optimal design with \\(\\lambda = 0.1\\). Additionally, these three designs are depicted in a joint plot. ## # A tibble: 3 × 3 ## type design average_n2 ## &lt;chr&gt; &lt;list&gt; &lt;dbl&gt; ## 1 No Penalization on AvN2 &lt;TwStgDsg&gt; 47.6 ## 2 Penalization on AvN2 with lambda = 0.01 &lt;TwStgDsg&gt; 46.6 ## 3 Penalization on AvN2 with lambda = 0.1 &lt;TwStgDsg&gt; 38.9 "],["scenarioVI.html", "7 Scenario VI: binomial distribution, point prior 7.1 Details 7.2 Variant VI-1: Minimizing Expected Sample Size Under Point Prior 7.3 Variant VI-2: Minimizing Expected Sample Size under Null Hypothesis 7.4 Variant VI-3: Conditional Power constraint", " 7 Scenario VI: binomial distribution, point prior 7.1 Details In this scenario, the implemented normal approximation of the binomial distribution is evaluated. There are two treatment groups \\(E\\) (experimental) and \\(C\\) (control) and the outcome of interest is the event rate in both groups. The event rate in the control group is assumed to equal \\(p_C = 0.3\\). Under the null hypothesis, the rate difference \\(p_E - p_C = 0\\) is assumed. Under the alternative, the rate difference is assumed to equal \\(p_E - p_C = 0.2\\). Type one error rate should be protected at 2.5% and the design’s power should be at least 90%. # data distribution and hypotheses datadist &lt;- Binomial(rate_control = 0.3, two_armed = TRUE) H_0 &lt;- PointMassPrior(.0, 1) prior &lt;- PointMassPrior(.2, 1) # define constraints alpha &lt;- 0.025 min_power &lt;- 0.9 toer_cnstr &lt;- Power(datadist, H_0) &lt;= alpha pow_cnstr &lt;- Power(datadist, prior) &gt;= min_power 7.2 Variant VI-1: Minimizing Expected Sample Size Under Point Prior In this variant, it is evaluated whether the optimization leads to more efficient designs and is plausible with published results. 7.2.1 Objective Expected sample size under the alternative point mass prior \\(\\delta = 0.2\\) is minimized. ess &lt;- ExpectedSampleSize(datadist, prior) 7.2.2 Constraints No additional constraints are considered. 7.2.3 Initial Designs For this example, the optimal one-stage, group-sequential, and generic two-stage designs are computed. The initial design for the one-stage case is determined heuristically and both the group sequential and the generic two-stage designs are optimized starting from the corresponding group-sequential design as computed by the rpact package. order &lt;- 7L # data frame of initial designs tbl_designs &lt;- tibble( type = c(&quot;one-stage&quot;, &quot;group-sequential&quot;, &quot;two-stage&quot;), initial = list( OneStageDesign(200, 2.0), rpact_design(datadist, 0.2, 0.025, 0.9, TRUE, order), TwoStageDesign(rpact_design(datadist, 0.2, 0.025, 0.9, TRUE, order))) ) The order of integration is set to 7. 7.2.4 Optimization tbl_designs &lt;- tbl_designs %&gt;% mutate( optimal = purrr::map(initial, ~minimize( ess, subject_to( toer_cnstr, pow_cnstr ), initial_design = ., opts = opts)) ) 7.2.5 Test Cases To avoid improper solutions, it is first verified that the maximum number of iterations was not exceeded in any of the three cases. tbl_designs %&gt;% transmute( type, iterations = purrr::map_int(tbl_designs$optimal, ~.$nloptr_return$iterations) ) %&gt;% {print(.); .} %&gt;% {testthat::expect_true(all(.$iterations &lt; opts$maxeval))} ## # A tibble: 3 × 2 ## type iterations ## &lt;chr&gt; &lt;int&gt; ## 1 one-stage 28 ## 2 group-sequential 1775 ## 3 two-stage 5102 Next, the type one error rate and power constraints are verified for all three designs by simulation: tbl_designs %&gt;% transmute( type, toer = purrr::map(tbl_designs$optimal, ~sim_pr_reject(.[[1]], .0, datadist)$prob), power = purrr::map(tbl_designs$optimal, ~sim_pr_reject(.[[1]], .2, datadist)$prob) ) %&gt;% unnest(., cols = c(toer, power)) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$toer &lt;= alpha * (1 + tol))) testthat::expect_true(all(.$power &gt;= min_power * (1 - tol))) } ## # A tibble: 3 × 3 ## type toer power ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage 0.0251 0.900 ## 2 group-sequential 0.0249 0.900 ## 3 two-stage 0.0249 0.901 Since the degrees of freedom of the three design classes are ordered as ‘two-stage’ &gt; ‘group-sequential’ &gt; ‘one-stage’, the expected sample sizes (under the alternative) should be ordered in reverse (‘two-stage’ smallest). Additionally, expected sample sizes under both null and alternative are computed both via evaluate() and simulation-based. ess0 &lt;- ExpectedSampleSize(datadist, H_0) tbl_designs %&gt;% mutate( ess = map_dbl(optimal, ~evaluate(ess, .$design) ), ess_sim = map_dbl(optimal, ~sim_n(.$design, .2, datadist)$n ), ess0 = map_dbl(optimal, ~evaluate(ess0, .$design) ), ess0_sim = map_dbl(optimal, ~sim_n(.$design, .0, datadist)$n ) ) %&gt;% {print(.); .} %&gt;% { # sim/evaluate same under alternative? testthat::expect_equal(.$ess, .$ess_sim, tolerance = tol_n, scale = 1) # sim/evaluate same under null? testthat::expect_equal(.$ess0, .$ess0_sim, tolerance = tol_n, scale = 1) # monotonicity with respect to degrees of freedom testthat::expect_true(all(diff(.$ess) &lt; 0)) } ## # A tibble: 3 × 7 ## type initial optimal ess ess_sim ess0 ess0_sim ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage &lt;OnStgDsg&gt; &lt;adptrOpR [3]&gt; 124 124 124 124 ## 2 group-sequential &lt;GrpSqntD&gt; &lt;adptrOpR [3]&gt; 96.2 96.2 89.7 89.8 ## 3 two-stage &lt;TwStgDsg&gt; &lt;adptrOpR [3]&gt; 94.3 94.2 98.5 98.6 The expected sample size under the alternative must be lower or equal than the expected sample size of the initial rpact group-sequential design that is based on the inverse normal combination test. testthat::expect_lte( evaluate(ess, tbl_designs %&gt;% filter(type == &quot;group-sequential&quot;) %&gt;% pull(optimal) %&gt;% .[[1]] %&gt;% .$design ), evaluate(ess, tbl_designs %&gt;% filter(type == &quot;group-sequential&quot;) %&gt;% pull(initial) %&gt;% .[[1]] ) ) Finally, the rpact group-sequential design, the optimal group-sequential design, and the optimal generic two-stage design are plotted to allow visual inspection. 7.3 Variant VI-2: Minimizing Expected Sample Size under Null Hypothesis 7.3.1 Objective Expected sample size under the null hypothesis is minimized. 7.3.2 Constraints The constraints remain unchanged. 7.3.3 Initial design Optimization under the null favors a monotonically increasing sample size function, and thus also a different shape of the \\(c_2\\) function. Thus, we start with a constant \\(c_2\\) function by heuristically setting it to \\(2\\) on the continuation area. Also, optimizing under the null favors extremely conservative boundaries for early efficacy stopping and we thus impose a fairly liberal upper bound of \\(3\\) for early efficacy stopping. init_design_h0 &lt;- tbl_designs %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% pull(initial) %&gt;% .[[1]] init_design_h0@c2_pivots &lt;- rep(2, order) ub_design &lt;- TwoStageDesign( 3 * init_design_h0@n1, 2, 3, rep(300, order), rep(3.0, order) ) 7.3.4 Optimization The optimal two-stage design is now computed. opt_h0 &lt;- minimize( ess0, subject_to( toer_cnstr, pow_cnstr ), initial_design = init_design_h0, upper_boundary_design = ub_design, opts = opts ) 7.3.5 Test cases Make sure that the optimization algorithm converged within the set maximum number of iterations: opt_h0$nloptr_return$iterations %&gt;% {print(.); .} %&gt;% {testthat::expect_true(. &lt; opts$maxeval)} ## [1] 12245 The \\(n_2\\) function of the optimal two-stage design is expected to be monotonously increasing. expect_true( all(diff(opt_h0$design@n2_pivots) &gt; 0) ) Next, the type one error rate and power constraints are tested. tbl_performance &lt;- tibble( delta = c(.0, .2) ) %&gt;% mutate( power = map( delta, ~evaluate( Power(datadist, PointMassPrior(., 1)), opt_h0$design) ), power_sim = map( delta, ~sim_pr_reject(opt_h0$design, ., datadist)$prob), ess = map( delta, ~evaluate(ExpectedSampleSize( datadist, PointMassPrior(., 1) ), opt_h0$design) ), ess_sim = map( delta, ~sim_n(opt_h0$design, . ,datadist)$n ) ) %&gt;% unnest(., cols = c(power, power_sim, ess, ess_sim)) print(tbl_performance) ## # A tibble: 2 × 5 ## delta power power_sim ess ess_sim ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0.0250 0.0250 74.8 74.9 ## 2 0.2 0.901 0.901 149. 149. testthat::expect_lte( tbl_performance %&gt;% filter(delta == 0) %&gt;% pull(power_sim), alpha * (1 + tol) ) testthat::expect_gte( tbl_performance %&gt;% filter(delta == 0.2) %&gt;% pull(power_sim), min_power * (1 - tol) ) # make sure that evaluate() leads to same results testthat::expect_equal( tbl_performance$power, tbl_performance$power_sim, tol = tol, scale = 1 ) testthat::expect_equal( tbl_performance$ess, tbl_performance$ess_sim, tol = tol_n, scale = 1 ) The expected sample size under the null must be lower or equal than the expected sample size of the initial rpact group-sequential design. testthat::expect_gte( evaluate(ess0, tbl_designs %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% pull(initial) %&gt;% .[[1]] ), evaluate(ess0, opt_h0$design) ) 7.4 Variant VI-3: Conditional Power constraint 7.4.1 Objective Same as in VI-1, the expected sample size under the alternative is minimized. 7.4.2 Constraints Besides the previous global type one error rate and power constraints, an additional constraint on conditional power is imposed. cp &lt;- ConditionalPower(datadist, prior) cp_cnstr &lt;- cp &gt;= .85 7.4.3 Initial Design The same initial (generic two-stage) design as in VI-1 is used. 7.4.4 Optimization opt_cp &lt;- minimize( ess, subject_to( toer_cnstr, pow_cnstr, cp_cnstr # new constraint ), initial_design = tbl_designs %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% pull(initial) %&gt;% .[[1]], opts = opts ) 7.4.5 Test Cases Check if the optimization converged. opt_cp$nloptr_return$iterations %&gt;% {print(.); .} %&gt;% {testthat::expect_true(. &lt; opts$maxeval)} ## [1] 3131 Check constraints. tbl_performance &lt;- tibble( delta = c(.0, .2) ) %&gt;% mutate( power = map( delta, ~evaluate( Power(datadist, PointMassPrior(., 1)), opt_cp$design) ), power_sim = map( delta, ~sim_pr_reject(opt_cp$design, ., datadist)$prob), ess = map( delta, ~evaluate(ExpectedSampleSize( datadist, PointMassPrior(., 1) ), opt_cp$design) ), ess_sim = map( delta, ~sim_n(opt_cp$design, . ,datadist)$n ) ) %&gt;% unnest(., cols = c(power, power_sim, ess, ess_sim)) print(tbl_performance) ## # A tibble: 2 × 5 ## delta power power_sim ess ess_sim ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0.0250 0.0249 91.6 91.6 ## 2 0.2 0.899 0.899 94.5 94.5 testthat::expect_lte( tbl_performance %&gt;% filter(delta == 0) %&gt;% pull(power_sim), alpha * (1 + tol) ) testthat::expect_gte( tbl_performance %&gt;% filter(delta == 0.2) %&gt;% pull(power_sim), min_power * (1 - tol) ) # make sure that evaluate() leads to same results testthat::expect_equal( tbl_performance$power, tbl_performance$power_sim, tol = tol, scale = 1 ) testthat::expect_equal( tbl_performance$ess, tbl_performance$ess_sim, tol = tol_n, scale = 1 ) The conditional power constraint is evaluated and tested on a grid over the continuation region (both simulated via numerical integration). tibble( x1 = seq(opt_cp$design@c1f, opt_cp$design@c1e, length.out = 25), cp = map_dbl(x1, ~evaluate(cp, opt_cp$design, .)), cp_sim = map_dbl(x1, function(x1) { x2 &lt;- simulate(datadist, 10^6, n2(opt_cp$design, x1), .2, 42) rej &lt;- ifelse(x2 &gt; c2(opt_cp$design, x1), 1, 0) return(mean(rej)) }) ) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$cp &gt;= 0.85 * (1 - tol))) testthat::expect_true(all(.$cp_sim &gt;= 0.85 * (1 - tol))) testthat::expect_true(all(abs(.$cp - .$cp_sim) &lt;= tol)) } ## # A tibble: 25 × 3 ## x1 cp cp_sim ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.586 0.850 0.849 ## 2 0.657 0.850 0.850 ## 3 0.727 0.851 0.851 ## 4 0.798 0.851 0.851 ## 5 0.868 0.849 0.848 ## 6 0.939 0.849 0.849 ## 7 1.01 0.850 0.849 ## 8 1.08 0.850 0.850 ## 9 1.15 0.851 0.851 ## 10 1.22 0.852 0.851 ## # ℹ 15 more rows Finally, the expected sample size under the alternative prior should be larger than in the case without the constraint VI-1. testthat::expect_gte( evaluate(ess, opt_cp$design), evaluate( ess, tbl_designs %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% pull(optimal) %&gt;% .[[1]] %&gt;% .$design ) ) "],["scenarioVII.html", "8 Scenario VII: binomial distribution, Gaussian prior 8.1 Details 8.2 Variant VII-1: Minimizing Expected Sample Size under Continuous Prior 8.3 Variant VII-2: Conditional Power Constraint 8.4 Plot Two-Stage Designs", " 8 Scenario VII: binomial distribution, Gaussian prior 8.1 Details In this scenario, we revisit the case from ScenarioVI, but are not assuming a point prior anymore. We assume \\(p_C=0.3\\) for the event rate in the control group. The parameter which can be varied is the event rate in the experimental group \\(p_E\\) and we assume that the rate difference \\(p_E-p_C \\sim \\textbf{1}_{(-0.29,0.69)} \\mathcal{N}(0.2,0.2)\\).The restriction to the interval \\((-0.29,0.69)\\) is necessary to ensure that the parameter \\(p_E\\) does not become smaller than \\(0\\) or larger than \\(1\\). In order to fulfill regulatory considerations, the type one error rate is still protected under the point prior \\(\\delta=0\\) at the level of significance \\(\\alpha=0.025\\). Since effect sizes less than a minimal clinically relevant effect do not show evidence against the null hypothesis, we assume a clinically relevant effect size \\(\\delta =0.0\\) and condition the prior on values \\(\\delta &gt; 0\\) in order to compute the expected power. We assume a minimal expected power of at least \\(0.8\\). # data distribution and priors datadist &lt;- Binomial(rate_control = 0.3, two_armed = TRUE) H_0 &lt;- PointMassPrior(.0, 1) prior &lt;- ContinuousPrior(function(x) 1 / (pnorm(0.69, 0.2, 0.2) - pnorm(-0.29, 0.2, 0.2)) * dnorm(x, 0.2, 0.2), support = c(-0.29, 0.69), tighten_support = TRUE) # define constraints on type one error rate and expected power alpha &lt;- 0.025 min_epower &lt;- 0.8 toer_cnstr &lt;- Power(datadist, H_0) &lt;= alpha epow_cnstr &lt;- Power(datadist, condition(prior, c(0.0, 0.69))) &gt;= min_epower 8.2 Variant VII-1: Minimizing Expected Sample Size under Continuous Prior 8.2.1 Objective Expected sample size under the full prior is minimized, i.e., \\(\\boldsymbol{E}\\big[n(\\mathscr{D})\\big]\\). ess &lt;- ExpectedSampleSize(datadist, prior) 8.2.2 Constraints No additional constraints are considered. 8.2.3 Initial Designs For this example, the optimal one-stage, group-sequential, and generic two-stage designs are computed. The initial design for the one-stage case is determined heuristically and both the group sequential and the generic two-stage designs are optimized starting from the corresponding group-sequential design as computed by the rpact package. order &lt;- 7L # data frame of initial designs tbl_designs &lt;- tibble( type = c(&quot;one-stage&quot;, &quot;group-sequential&quot;, &quot;two-stage&quot;), initial = list( OneStageDesign(200, 2.0), rpact_design(datadist, 0.2, 0.025, 0.8, TRUE, order), TwoStageDesign(get_initial_design(0.2, 0.025, 0.2, &quot;two-stage&quot;, dist = datadist) ))) The order of integration is set to 7. 8.2.4 Optimization tbl_designs &lt;- tbl_designs %&gt;% mutate( optimal = purrr::map(initial, ~minimize( ess, subject_to( toer_cnstr, epow_cnstr ), initial_design = ., opts = opts)) ) 8.2.5 Test Cases To avoid improper solutions, it is first verified that the maximum number of iterations was not exceeded in any of the three cases. tbl_designs %&gt;% transmute( type, iterations = purrr::map_int(tbl_designs$optimal, ~.$nloptr_return$iterations) ) %&gt;% {print(.); .} %&gt;% {testthat::expect_true(all(.$iterations &lt; opts$maxeval))} ## # A tibble: 3 × 2 ## type iterations ## &lt;chr&gt; &lt;int&gt; ## 1 one-stage 21 ## 2 group-sequential 642 ## 3 two-stage 22550 Furthermore, the type one error rate constraint needs to be tested. tbl_designs %&gt;% transmute( type, toer = purrr::map(tbl_designs$optimal, ~sim_pr_reject(.[[1]], .0, datadist)$prob) ) %&gt;% unnest(., cols = c(toer)) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$toer &lt;= alpha * (1 + tol))) } ## # A tibble: 3 × 2 ## type toer ## &lt;chr&gt; &lt;dbl&gt; ## 1 one-stage 0.0251 ## 2 group-sequential 0.0250 ## 3 two-stage 0.0249 The optimal two-stage design is more flexible than the other two designs, so the expected sample sizes under the prior should be ordered upwards as follows: optimal two-stage design &lt; group sequential &lt; one-stage. We additionally compare the simulated and theoretical outcomes of the sample size under the null. essh0 &lt;- ExpectedSampleSize(datadist, H_0) tbl_designs %&gt;% mutate( ess = map_dbl(optimal, ~evaluate(ess, .$design) ), essh0 = map_dbl(optimal, ~evaluate(essh0, .$design) ), essh0_sim = map_dbl(optimal, ~sim_n(.$design, .0, datadist)$n ) ) %&gt;% {print(.); .} %&gt;% { # sim/evaluate same under null? testthat::expect_equal(.$essh0, .$essh0_sim, tolerance = tol_n, scale = 1) # monotonicity with respect to degrees of freedom testthat::expect_true(all(diff(.$ess) &lt; 0)) } ## # A tibble: 3 × 6 ## type initial optimal ess essh0 essh0_sim ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage &lt;OnStgDsg&gt; &lt;adptrOpR [3]&gt; 238 238 238 ## 2 group-sequential &lt;GrpSqntD&gt; &lt;adptrOpR [3]&gt; 103. 161. 161. ## 3 two-stage &lt;TwStgDsg&gt; &lt;adptrOpR [3]&gt; 99.2 169. 169. 8.3 Variant VII-2: Conditional Power Constraint 8.3.1 Objective As in VariantVII-1, the expected sample size under the full prior is minimized. 8.3.2 Constraints In addition to the constraints on type one error rate and expected power, a constraint on conditional power to be larger than \\(0.7\\) is included. cp &lt;- ConditionalPower(datadist, condition(prior, c(0, 0.69))) cp_cnstr &lt;- cp &gt;= 0.7 8.3.3 Initial Design We reuse the previous inital design. 8.3.4 Optimization opt_cp &lt;- minimize( ess, subject_to( toer_cnstr, epow_cnstr, cp_cnstr ), initial_design = tbl_designs$initial[[3]], opts = opts ) 8.3.5 Test Cases As always, we start checking whether the maximum number of iterations was reached or not. testthat::expect_true(opt_cp$nloptr_return$iterations &lt; opts$maxeval) print(opt_cp$nloptr_return$iterations) ## [1] 17551 The type one error rate is tested via simulation and compared to the value obtained by evaluate(). tbl_toer &lt;- tibble( toer = evaluate(Power(datadist, H_0), opt_cp$design), toer_sim = sim_pr_reject(opt_cp$design, .0, datadist)$prob ) print(tbl_toer) ## # A tibble: 1 × 2 ## toer toer_sim ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.0250 0.0249 testthat::expect_true(tbl_toer$toer &lt;= alpha * (1 + tol)) testthat::expect_true(tbl_toer$toer_sim &lt;= alpha * (1 + tol)) The conditional power is evaluated via numerical integration on several points inside the continuation region and it is tested whether the constraint is fulfilled on all these points. tibble( x1 = seq(opt_cp$design@c1f, opt_cp$design@c1e, length.out = 25), cp = map_dbl(x1, ~evaluate(cp, opt_cp$design, .)) ) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$cp &gt;= 0.7 * (1 - tol))) } ## # A tibble: 25 × 2 ## x1 cp ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.190 0.699 ## 2 0.288 0.700 ## 3 0.387 0.700 ## 4 0.486 0.700 ## 5 0.585 0.700 ## 6 0.684 0.698 ## 7 0.783 0.697 ## 8 0.882 0.699 ## 9 0.981 0.709 ## 10 1.08 0.725 ## # ℹ 15 more rows Due to the additional constraint, this variant should show a larger expected sample size. testthat::expect_gte( evaluate(ess, opt_cp$design), evaluate( ess, tbl_designs %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% pull(optimal) %&gt;% .[[1]] %&gt;% .$design ) ) 8.4 Plot Two-Stage Designs The optimal two-stage designs are plotted together. "],["scenarioVIII.html", "9 Scenario VIII: large effect, unknown variance 9.1 Details 9.2 Variant VIII-1: Minimizing Expected Sample Size under Point Prior 9.3 Variant VIII-2: Comparison to Normal Distribution", " 9 Scenario VIII: large effect, unknown variance 9.1 Details In this scenario, we investigate the scenario of a large effect with unknown common variance \\(\\sigma\\). The test statistic then follows a \\(t\\)-distribution. For a large sample size, the \\(t\\)-distribution can be approximated by the normal distribution and we find ourselves in Scenario I. The larger the assumed effect size in the alternative, the lower the necessary number of subjects to achieve a minimum power. Thus, we choose an effect size of \\(\\delta=1\\) with point prior distribution. The null hypothesis is given by \\(\\mathcal{H}_0: \\delta \\leq 0\\). The maximal type one error is bounded by \\(\\alpha=0.025\\) and at the point alternative of \\(\\delta=1\\) the power should be at least \\(0.9\\). #data distributions and hypothesis datadist &lt;- Student(two_armed=TRUE) H_0 &lt;- PointMassPrior(.0, 1) prior &lt;- PointMassPrior(1.0, 1) #define constraints alpha &lt;- 0.025 min_power &lt;- 0.9 toer_cnstr &lt;- Power(datadist,H_0) &lt;= alpha pow_cnstr &lt;- Power(datadist,prior) &gt;= min_power 9.2 Variant VIII-1: Minimizing Expected Sample Size under Point Prior 9.2.1 Objective Firstly, we minimize the expected sample size under the alternative, e.g. \\(\\boldsymbol{E}\\big[n(\\mathcal{D})\\big]\\). ess &lt;- ExpectedSampleSize(datadist, prior) 9.2.2 Constraints No additional constraints beside type one error rate and power are considered in this variant. 9.2.3 Initial Designs For this example, the optimal one-stage, group-sequential, and generic two-stage designs are computed. The initial design for the one-stage case is determined heuristically. Both the group sequential and the generic two-stage designs are optimized starting from the corresponding group-sequential design as computed by the rpact package. order &lt;- 7L # data frame of initial designs tbl_designs &lt;- tibble( type = c(&quot;one-stage&quot;, &quot;group-sequential&quot;, &quot;two-stage&quot;), initial = list( OneStageDesign(20, 2.0), rpact_design(datadist, 1.0, 0.025, 0.9, TRUE, order), TwoStageDesign(rpact_design(datadist, 1.0, 0.025, 0.9, TRUE, order))) ) 9.2.4 Optimization tbl_designs &lt;- tbl_designs %&gt;% mutate( optimal = purrr::map(initial, ~minimize( ess, subject_to( toer_cnstr, pow_cnstr ), initial_design = ., opts = opts)) ) 9.2.5 Test Cases To avoid improper solutions, it is first verified that the maximum number of iterations was not exceeded in any of the three cases. tbl_designs %&gt;% transmute( type, iterations = purrr::map_int(tbl_designs$optimal, ~.$nloptr_return$iterations) ) %&gt;% {print(.); .} %&gt;% {testthat::expect_true(all(.$iterations &lt; opts$maxeval))} ## # A tibble: 3 × 2 ## type iterations ## &lt;chr&gt; &lt;int&gt; ## 1 one-stage 19 ## 2 group-sequential 1878 ## 3 two-stage 4574 Next, the type one error rate and power constraints are verified for all three designs by simulation: tbl_designs %&gt;% transmute( type, toer = purrr::map(tbl_designs$optimal, ~sim_pr_reject(.[[1]], .0, datadist)$prob), power = purrr::map(tbl_designs$optimal, ~sim_pr_reject(.[[1]], 1.0, datadist)$prob) ) %&gt;% unnest(., cols = c(toer, power)) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$toer &lt;= alpha * (1 + tol))) testthat::expect_true(all(.$power &gt;= min_power * (1 - tol))) } ## # A tibble: 3 × 3 ## type toer power ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage 0.0251 0.899 ## 2 group-sequential 0.0250 0.898 ## 3 two-stage 0.0247 0.897 The \\(n_2\\) function of the optimal two-stage design is expected to be monotonously decreasing: expect_true( all(diff( # get optimal two-stage design n2 pivots tbl_designs %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% {.[[&quot;optimal&quot;]][[1]]$design@n2_pivots} ) &lt; 0) ) Since the optimal two-stage design is more flexible than the optimal group-sequential design (constant \\(n_2\\) function) and this is more flexible than the optimal one-stage design (no second stage), the expected sample sizes under the prior should be ordered in the opposite way. Additionally, expected sample sizes under the null hypothesis are computed both via evaluate() and simulation-based. tbl_designs %&gt;% mutate( ess = map_dbl(optimal, ~evaluate(ess, .$design) ), ess_sim = map_dbl(optimal, ~sim_n(.$design, 1, datadist)$n ), ess0 = map_dbl(optimal, ~evaluate(ess0, .$design) ), ess0_sim = map_dbl(optimal, ~sim_n(.$design, .0, datadist)$n ) ) %&gt;% {print(.); .} %&gt;% { # sim/evaluate same under alternative? testthat::expect_equal(.$ess, .$ess_sim, tolerance = tol_n, scale = 1) # sim/evaluate same under null? testthat::expect_equal(.$ess0, .$ess0_sim, tolerance = tol_n, scale = 1) # monotonicity with respect to degrees of freedom testthat::expect_true(all(diff(.$ess) &lt; 0)) } ## # A tibble: 3 × 7 ## type initial optimal ess ess_sim ess0 ess0_sim ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage &lt;OnStgDsg&gt; &lt;adptrOpR [3]&gt; 22 22 22 22 ## 2 group-sequential &lt;GrpSqntD&gt; &lt;adptrOpR [3]&gt; 17.3 17.3 15.7 15.7 ## 3 two-stage &lt;TwStgDsg&gt; &lt;adptrOpR [3]&gt; 17.0 17.0 16.7 16.6 The expected sample size under the alternative must be lower or equal than the expected sample size of the initial rpact group-sequential design that is based on the inverse normal combination test. testthat::expect_lte( evaluate(ess, tbl_designs %&gt;% filter(type == &quot;group-sequential&quot;) %&gt;% pull(optimal) %&gt;% .[[1]] %&gt;% .$design ), evaluate(ess, tbl_designs %&gt;% filter(type == &quot;group-sequential&quot;) %&gt;% pull(initial) %&gt;% .[[1]] ) ) 9.3 Variant VIII-2: Comparison to Normal Distribution 9.3.1 Generate Comparison Design We now compare the expected sample size of this scenario to the expected sample size when we assume that the variance is known. Thus, we need to find the optimal designs with normal distributed test statistic. These steps are completely analogous to scenario I. datadistnorm &lt;- Normal(two_armed=TRUE) H_0norm &lt;- PointMassPrior(.0,1) priornorm &lt;- PointMassPrior(1.0,1) toernorm &lt;- Power(datadistnorm,H_0norm) &lt;= alpha pownorm &lt;- Power(datadistnorm,priornorm) &gt;= min_power We minimize the expected sample size under the alternative. essnorm &lt;- ExpectedSampleSize(datadistnorm,priornorm) We now choose different initial designs since we do not use the \\(t\\)-distribution anymore. tbl_designsnorm &lt;- tibble( type = c(&quot;one-stage&quot;, &quot;group-sequential&quot;, &quot;two-stage&quot;), initial = list( OneStageDesign(20, 2.0), rpact_design(datadist, 1.0, 0.025, 0.9, TRUE, order), TwoStageDesign(rpact_design(datadist, 1.0, 0.025, 0.9, TRUE, order))) ) tbl_designsnorm &lt;- tbl_designsnorm %&gt;% mutate( optimal = purrr::map(initial, ~minimize( ess, subject_to( toernorm, pownorm ), initial_design = ., opts = opts)) ) 9.3.2 Test Cases In all of the three designs, we should see that the expected sample size under the normal distributed test statistic is lower than the expected sample size when we use the \\(t\\)-distribution. essstudent &lt;- map_dbl(tbl_designs$optimal,~evaluate(ess,.$design)) essnorm &lt;- map_dbl(tbl_designsnorm$optimal,~evaluate(ess,.$design)) ## Student ## 22 17.3488 16.97228 ## Normal ## 21 15.87601 15.59286 diff &lt;- essstudent-essnorm testthat::expect_true(all(diff &gt; 0)) "],["scenario-ix-time-to-event-endpoints.html", "10 Scenario IX: time-to-event endpoints 10.1 Details 10.2 Variant IX-1: Minimizing expected number of events under point prior", " 10 Scenario IX: time-to-event endpoints 10.1 Details In this scenario, we visit a different scenario: Instead of continuous or binary endpoints, we now consider time-to-event endpoints. Therefore, we conduct a log-rank test, for which adoptr provides the normal approximation of the test statistic. In order to obtain a one-parametric statistic, we need to fix the event probability \\(d\\) during the trial. We assume that a hazard ratio \\(\\theta&gt;1\\) implies favorable results. The null-hypothesis is given by \\(\\mathcal{H}_0:\\theta\\leq 1\\). In both of the following two scenarios, we assume a constant event rate of \\(d=0.7\\) and the type one error should be bounded by \\(\\alpha&lt;0.025\\) and a power of \\(0.8\\) is necessary. Attention: adoptr calculates the number of necessary events, not the sample size. Thus, e.g. the function ExpectedSampleSize does not really represent the expected sample size, but the expected number of events. The sample size can be calculated by dividing the number of events by the event rate. datadist &lt;- Survival(0.7, two_armed = TRUE) H_0 &lt;- PointMassPrior(1.0, 1) alpha &lt;- 0.025 min_power &lt;- 0.8 10.2 Variant IX-1: Minimizing expected number of events under point prior Under the alternative, we us a hazard ratio of \\(\\theta=1.4\\) for the point prior of the alternative. prior &lt;- PointMassPrior(1.4, 1) toer_cnstr &lt;- Power(datadist, H_0) &lt;= alpha pow_cnstr &lt;- Power(datadist, prior) &gt;= min_power 10.2.1 Objective The expected number of events under the alternative is minimized. ess &lt;- ExpectedNumberOfEvents(datadist, prior) 10.2.2 Constraints No additional constraints besides type one and type two error are considered in this variant. 10.2.3 Initial Design The initial group sequential, two-stage and one-stage designs are chosen heuristically. order &lt;- 7L # data frame of initial designs tbl_designs &lt;- tibble( type = c(&quot;one-stage&quot;, &quot;group-sequential&quot;, &quot;two-stage&quot;), initial = list( OneStageDesign(150, 2.0, event_rate = 0.7), GroupSequentialDesign(75, 0.8, 2.3, 170, c2_pivots=c(0.9, 1.1, 1.3, 1.5, 1.7, 1.9, 2.1), event_rate = 0.7), TwoStageDesign(75, 0.8, 2.3, c(220, 200, 170, 150, 140, 130, 120), c2_pivots = c(0.9, 1.1, 1.3, 1.5, 1.7, 1.9, 2.1), event_rate = 0.7)) ) The order of the integration is set to 7. 10.2.4 Optimization tbl_designs &lt;- tbl_designs %&gt;% mutate( optimal = purrr::map(initial, ~minimize( ess, subject_to( toer_cnstr, pow_cnstr ), initial_design = ., opts = opts)) ) 10.2.5 Test cases We first check that the maximum number of iterations was not reached. tbl_designs %&gt;% transmute( type, iterations = purrr::map_int(tbl_designs$optimal, ~.$nloptr_return$iterations) ) %&gt;% {print(.); .} %&gt;% {testthat::expect_true(all(.$iterations &lt; opts$maxeval))} ## # A tibble: 3 × 2 ## type iterations ## &lt;chr&gt; &lt;int&gt; ## 1 one-stage 22 ## 2 group-sequential 1259 ## 3 two-stage 2620 Besides, we check whether the type one error was not exceeded and the necessary power is reached. tbl_designs %&gt;% transmute( type, toer = purrr::map(tbl_designs$optimal, ~sim_pr_reject(.[[1]], 1.0, datadist)$prob), power = purrr::map(tbl_designs$optimal, ~sim_pr_reject(.[[1]], 1.4, datadist)$prob) ) %&gt;% unnest(., cols = c(toer, power)) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$toer &lt;= alpha * (1 + tol))) testthat::expect_true(all(.$power &gt;= min_power * (1 - tol))) } ## # A tibble: 3 × 3 ## type toer power ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage 0.0251 0.801 ## 2 group-sequential 0.0250 0.798 ## 3 two-stage 0.0250 0.801 Since the degrees of freedom of the three design classes are ordered as ‘two-stage’ &gt; ‘group-sequential’ &gt; ‘one-stage’, the expected sample sizes (under the alternative) should be ordered in reverse (‘two-stage’ smallest). Additionally, expected sample sizes under both null and alternative are computed both via evaluate() and simulation-based. ess0 &lt;- ExpectedSampleSize(datadist, H_0) tbl_designs %&gt;% mutate( ess = map_dbl(optimal, ~evaluate(ess, .$design) ), ess_sim = map_dbl(optimal, ~sim_n(.$design, 1.4, datadist)$n ), ess0 = map_dbl(optimal, ~evaluate(ess0, .$design) ), ess0_sim = map_dbl(optimal, ~sim_n(.$design, 1.0, datadist)$n ) ) %&gt;% {print(.); .} %&gt;% { # sim/evaluate same under alternative? testthat::expect_equal(.$ess, .$ess_sim, tolerance = tol_n, scale = 1) # sim/evaluate same under null? testthat::expect_equal(.$ess0, .$ess0_sim, tolerance = tol_n, scale = 1) # monotonicity with respect to degrees of freedom testthat::expect_true(all(diff(.$ess) &lt; 0)) } ## # A tibble: 3 × 7 ## type initial optimal ess ess_sim ess0 ess0_sim ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage &lt;OnStgDsS&gt; &lt;adptrOpR [3]&gt; 139 139 139 139 ## 2 group-sequential &lt;GrpSqnDS&gt; &lt;adptrOpR [3]&gt; 114. 114. 96.3 96.4 ## 3 two-stage &lt;TwStgDsS&gt; &lt;adptrOpR [3]&gt; 113. 113. 98.2 98.3 The expected sample size under the alternative must be lower or equal than the expected sample size of the initial rpact group-sequential design that is based on the inverse normal combination test. testthat::expect_lte( evaluate(ess, tbl_designs %&gt;% filter(type == &quot;group-sequential&quot;) %&gt;% pull(optimal) %&gt;% .[[1]] %&gt;% .$design ), evaluate(ess, tbl_designs %&gt;% filter(type == &quot;group-sequential&quot;) %&gt;% pull(initial) %&gt;% .[[1]] ) ) "],["scenario-x-chi-squared-distribution.html", "11 Scenario X: Chi-Squared Distribution 11.1 Details 11.2 Variant X-1: Contingeny table with binary endpoints 11.3 Variant X-2: Two-sided Z-test", " 11 Scenario X: Chi-Squared Distribution 11.1 Details In this scenario, we consider the case where the test statistic is Chi-squared distributed. It is useful when we conduct a test with more than two treatment arms or when we test two-sided with a normally distributed test statistic. In the first case, we assume binary endpoints, so we have a \\(2 \\times k\\) contingency table. In the second case, we conduct a two-sided Z-test. As the normal distribution is symmetric around \\(0\\), this test is equivalent to a one-sided test with test statistic \\(Z^2\\). 11.2 Variant X-1: Contingeny table with binary endpoints 11.2.1 Setup Under the alternative, we assume a response rate of \\(0.4\\) in the first group, \\(0.5\\) in the second and \\(0.6\\) in the third group. rate_vec &lt;- c(0.4, 0.5, 0.6) theta &lt;- get_tau_Pearson2xK(rate_vec) datadist &lt;- Pearson2xK(3) H_0 &lt;- PointMassPrior(.0, 1) prior &lt;- PointMassPrior(theta, 1) alpha &lt;- 0.025 min_power &lt;- 0.9 toer_cnstr &lt;- Power(datadist, H_0) &lt;= alpha pow_cnstr &lt;- Power(datadist,prior) &gt;= min_power 11.2.2 Objective The expected sample size under the alternative shall be minimized. ess &lt;- ExpectedSampleSize(datadist, prior) 11.2.3 Initial design The initial designs for the minimization process is chosen using the in-built function. tbl_designs &lt;- tibble( type = c(&quot;one-stage&quot;, &quot;group-sequential&quot;, &quot;two-stage&quot;), initial = list( get_initial_design(theta, alpha, 1- min_power, dist = datadist, type_design = &quot;one-stage&quot;), get_initial_design(theta, alpha, 1- min_power, dist = datadist, type_design = &quot;group-sequential&quot;), get_initial_design(theta, alpha, 1- min_power, dist = datadist, type_design = &quot;two-stage&quot;))) 11.2.4 Optimization tbl_designs &lt;- tbl_designs %&gt;% mutate( optimal = purrr::map(initial, ~minimize( ess, subject_to( toer_cnstr, pow_cnstr ), initial_design = ., opts = opts)) ) 11.2.5 Test Cases We first verify that the number of iterations was not exceeded in any of the three cases. tbl_designs %&gt;% transmute( type, iterations = purrr::map_int(tbl_designs$optimal, ~.$nloptr_return$iterations) ) %&gt;% {print(.); .} %&gt;% {testthat::expect_true(all(.$iterations &lt; opts$maxeval))} ## # A tibble: 3 × 2 ## type iterations ## &lt;chr&gt; &lt;int&gt; ## 1 one-stage 24 ## 2 group-sequential 6727 ## 3 two-stage 5422 We then check via simulation that the type I error and power constraints are fulfilled. tbl_designs %&gt;% transmute( type, toer = purrr::map(tbl_designs$optimal, ~sim_pr_reject(.[[1]], .0, datadist)$prob), power = purrr::map(tbl_designs$optimal, ~sim_pr_reject(.[[1]], theta , datadist)$prob) ) %&gt;% unnest(., cols = c(toer, power)) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$toer &lt;= alpha * (1 + tol))) testthat::expect_true(all(.$power &gt;= min_power * (1 - tol))) } ## # A tibble: 3 × 3 ## type toer power ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage 0.0251 0.900 ## 2 group-sequential 0.0249 0.900 ## 3 two-stage 0.0249 0.899 We expect the sample size function \\(n_2\\) to be monotonously decreasing. testthat::expect_true( all(diff( # get optimal two-stage design n2 pivots tbl_designs %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% {.[[&quot;optimal&quot;]][[1]]$design@n2_pivots} ) &lt; 0) ) Since the degrees of freedom of the three design classes are ordered as ‘two-stage’ &gt; ‘group-sequential’ &gt; ‘one-stage’, the expected sample sizes (under the alternative) should be ordered in reverse (‘two-stage’ smallest). Additionally, expected sample sizes under both null and alternative are computed both via evaluate() and simulation-based. ess0 &lt;- ExpectedSampleSize(datadist, H_0) tbl_designs %&gt;% mutate( ess = map_dbl(optimal, ~evaluate(ess, .$design) ), ess_sim = map_dbl(optimal, ~sim_n(.$design, theta, datadist)$n ), ess0 = map_dbl(optimal, ~evaluate(ess0, .$design) ), ess0_sim = map_dbl(optimal, ~sim_n(.$design, .0, datadist)$n ) ) %&gt;% {print(.); .} %&gt;% { # sim/evaluate same under alternative? testthat::expect_equal(.$ess, .$ess_sim, tolerance = tol_n, scale = 1) # sim/evaluate same under null? testthat::expect_equal(.$ess0, .$ess0_sim, tolerance = tol_n, scale = 1) # monotonicity with respect to degrees of freedom testthat::expect_true(all(diff(.$ess) &lt; 0)) } ## # A tibble: 3 × 7 ## type initial optimal ess ess_sim ess0 ess0_sim ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage &lt;OnStgDsg&gt; &lt;adptrOpR [3]&gt; 184 184 184 184 ## 2 group-sequential &lt;GrpSqntD&gt; &lt;adptrOpR [3]&gt; 157. 157. 154. 154. ## 3 two-stage &lt;TwStgDsg&gt; &lt;adptrOpR [3]&gt; 155. 155. 162. 162. The expected sample size under the alternative of the optimized designs should be lower than the sample size of the initial designs. testthat::expect_lte( evaluate(ess, tbl_designs %&gt;% pull(optimal) %&gt;% .[[1]] %&gt;% .$design ), evaluate(ess, tbl_designs %&gt;% pull(initial) %&gt;% .[[1]] ) ) 11.3 Variant X-2: Two-sided Z-test In the second variant, we want to conduct a two-sided test with normally distributed outcome. Unfortunately, a two-sided test in the setting of two-stage trials is more difficult to implement, as the decision whether to stop early or to continue cannot be expressed in the same way as usual (\\(Z &lt; c_f\\) for futility, \\(Z &gt; c_e\\) for efficacy, \\(Z \\in [c_f, c_e]\\) for continuation). In the two-sided test scenario, we would need to consider \\(|Z|\\), so \\(|Z| &lt; c_f\\) for futility, \\(|Z| &gt; c_e\\) for efficacy, \\(|Z| \\in [c_f, c_e]\\) for continuation. Unfortunately, this would lead to \\(4\\) necessary boundaries, which would not fit the adoptr-framework. If \\(Z \\sim \\mathcal{N}(0,1)\\) under the null, we can use the fact \\(Z^2 \\sim \\chi^2\\) and transform our two-sided test problem to a one-sided test. Hence, we stop early for futility if \\(Z^2 &lt; c_f\\), for efficacy if \\(Z^2 &gt; c_e\\) and we continue if \\(Z^2 \\in [c_f, c_e]\\), where \\(c_f\\) and \\(c_e\\) are calculated by adoptr using a \\(\\chi^2\\)-distribution. 11.3.1 Setup Under the alternative, we assume an effect size of \\(0.4\\). We want to get a Type I error \\(\\alpha \\leq 0.05\\) and our power should be higher than \\(0.8\\) theta &lt;- get_tau_ZSquared(0.4) datadist &lt;- ZSquared(two_armed = TRUE) H_0 &lt;- PointMassPrior(.0, 1) prior &lt;- PointMassPrior(theta, 1) alpha &lt;- 0.05 min_power &lt;- 0.8 toer_cnstr &lt;- Power(datadist, H_0) &lt;= alpha pow_cnstr &lt;- Power(datadist,prior) &gt;= min_power 11.3.2 Objective We minimize the expected sample size under the alternative. ess &lt;- ExpectedSampleSize(datadist, prior) 11.3.3 Initial designs The initial designs for the minimization process is chosen using the in-built function. tbl_designs &lt;- tibble( type = c(&quot;one-stage&quot;, &quot;group-sequential&quot;, &quot;two-stage&quot;), initial = list( get_initial_design(theta, alpha, 1- min_power, dist = datadist, type_design = &quot;one-stage&quot;), get_initial_design(theta, alpha, 1- min_power, dist = datadist, type_design = &quot;group-sequential&quot;), get_initial_design(theta, alpha, 1- min_power, dist = datadist, type_design = &quot;two-stage&quot;))) 11.3.4 Optimization tbl_designs &lt;- tbl_designs %&gt;% mutate( optimal = purrr::map(initial, ~minimize( ess, subject_to( toer_cnstr, pow_cnstr ), initial_design = ., opts = opts)) ) 11.3.5 Test We check that in none of the three cases the number of iterations was exceeded. tbl_designs %&gt;% transmute( type, iterations = purrr::map_int(tbl_designs$optimal, ~.$nloptr_return$iterations) ) %&gt;% {print(.); .} %&gt;% {testthat::expect_true(all(.$iterations &lt; opts$maxeval))} ## # A tibble: 3 × 2 ## type iterations ## &lt;chr&gt; &lt;int&gt; ## 1 one-stage 24 ## 2 group-sequential 2563 ## 3 two-stage 2383 We now verify the type I error and power constraints. To get better insights, we do not simulate the test statistic, but normally distributed outcomes and then square the test statistic. N &lt;- 10^6 simulation &lt;- function(design, theta, dist){ count &lt;- 0 for(i in 1:N){ n1 &lt;- n1(design) treatment &lt;- rnorm(n1, mean = theta) control &lt;- rnorm(n1) Z_square &lt;- (sqrt(n1 / 2) * (mean(treatment) - mean(control)))^2 if(Z_square &gt; design@c1e){ count &lt;- count + 1 } if(Z_square &gt;= design@c1f &amp; Z_square &lt;= design@c1e){ n2 &lt;- n2(design, Z_square) treatment2 &lt;- rnorm(n2, mean = theta) control2 &lt;- rnorm(n2) Z_final &lt;- (sqrt(n2 / 2) * (mean(treatment2) - mean(control2)))^2 if(Z_final &gt; c2(design, Z_square)){ count &lt;- count + 1 } } } return(list( prob = count / N)) } tbl_designs %&gt;% transmute( type, toer = purrr::map(tbl_designs$optimal, ~simulation(.[[1]], .0, datadist)$prob), power = purrr::map(tbl_designs$optimal, ~simulation(.[[1]], .4, datadist)$prob) ) %&gt;% unnest(., cols = c(toer, power)) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$toer &lt;= alpha * (1 + tol))) testthat::expect_true(all(.$power &gt;= min_power * (1 - tol))) } ## # A tibble: 3 × 3 ## type toer power ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage 0.0499 0.799 ## 2 group-sequential 0.0501 0.798 ## 3 two-stage 0.0499 0.798 The \\(n_2\\) function should be monotonously decreasing. testthat::expect_true( all(diff( # get optimal two-stage design n2 pivots tbl_designs %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% {.[[&quot;optimal&quot;]][[1]]$design@n2_pivots} ) &lt; 0) ) Since the degrees of freedom of the three design classes are ordered as ‘two-stage’ &gt; ‘group-sequential’ &gt; ‘one-stage’, the expected sample sizes (under the alternative) should be ordered in reverse (‘two-stage’ smallest). Additionally, expected sample sizes under both null and alternative are computed both via evaluate() and simulation-based. ess0 &lt;- ExpectedSampleSize(datadist, H_0) tbl_designs %&gt;% mutate( ess = map_dbl(optimal, ~evaluate(ess, .$design) ), ess_sim = map_dbl(optimal, ~sim_n(.$design, theta, datadist)$n ), ess0 = map_dbl(optimal, ~evaluate(ess0, .$design) ), ess0_sim = map_dbl(optimal, ~sim_n(.$design, .0, datadist)$n ) ) %&gt;% {print(.); .} %&gt;% { # sim/evaluate same under alternative? testthat::expect_equal(.$ess, .$ess_sim, tolerance = tol_n, scale = 1) # sim/evaluate same under null? testthat::expect_equal(.$ess0, .$ess0_sim, tolerance = tol_n, scale = 1) # monotonicity with respect to degrees of freedom testthat::expect_true(all(diff(.$ess) &lt; 0)) } ## # A tibble: 3 × 7 ## type initial optimal ess ess_sim ess0 ess0_sim ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage &lt;OnStgDsg&gt; &lt;adptrOpR [3]&gt; 98 98 98 98 ## 2 group-sequential &lt;GrpSqntD&gt; &lt;adptrOpR [3]&gt; 87.2 87.2 82.0 82.0 ## 3 two-stage &lt;TwStgDsg&gt; &lt;adptrOpR [3]&gt; 87.1 87.1 83.2 83.2 The optimized design should have a lower expected sample size than the initial designs. testthat::expect_lte( evaluate(ess, tbl_designs %&gt;% pull(optimal) %&gt;% .[[1]] %&gt;% .$design ), evaluate(ess, tbl_designs %&gt;% pull(initial) %&gt;% .[[1]] ) ) "],["scenario-xi-f-distribution.html", "12 Scenario XI: F-Distribution 12.1 Details 12.2 Variant XI-1: ANOVA", " 12 Scenario XI: F-Distribution 12.1 Details In this scenario, we compute the necessary sample size for a one-way ANOVA with \\(k\\) groups. The resulting test statistic is \\(F\\)-distributed with \\(k-1\\) and \\(nk-k\\) degrees of freedom, where \\(n\\) stands for the sample size per group. 12.2 Variant XI-1: ANOVA 12.2.1 Setup Under the alternative, we assume a mean of \\(0.0\\) in the first group, \\(0.4\\) in the second group and \\(0.2\\) in the third group. means &lt;- c(0, 0.4, 0.2) theta &lt;- get_tau_ANOVA(means) datadist &lt;- ANOVA(3) H_0 &lt;- PointMassPrior(0, 1) prior &lt;- PointMassPrior(theta, 1) alpha &lt;- 0.05 min_power &lt;- 0.8 toer_cnstr &lt;- Power(datadist, H_0) &lt;= alpha pow_cnstr &lt;- Power(datadist, prior) &gt;= min_power 12.2.2 Objective We want to minimize the expected sample size under the alternative. ess &lt;- ExpectedSampleSize(datadist, prior) 12.2.3 Initial Design The initial designs are chosen via the in-built function to create initial designs. tbl_designs &lt;- tibble( type = c(&quot;one-stage&quot;, &quot;group-sequential&quot;, &quot;two-stage&quot;), initial = list( get_initial_design(theta, alpha, 1 - min_power, &quot;one-stage&quot;, dist = datadist), get_initial_design(theta, alpha, 1 - min_power, &quot;group-sequential&quot;, dist = datadist), get_initial_design(theta, alpha, 1 - min_power, &quot;two-stage&quot;, dist = datadist) )) 12.2.4 Optimization tbl_designs &lt;- tbl_designs %&gt;% mutate( optimal = purrr::map(initial, ~minimize( ess, subject_to( toer_cnstr, pow_cnstr ), initial_design = ., opts = opts)) ) 12.2.5 Test Cases We first verify that in none of the three cases, the maximal number of iterations was exceeded. tbl_designs %&gt;% transmute( type, iterations = purrr::map_int(tbl_designs$optimal, ~.$nloptr_return$iterations) ) %&gt;% {print(.); .} %&gt;% {testthat::expect_true(all(.$iterations &lt; opts$maxeval))} ## # A tibble: 3 × 2 ## type iterations ## &lt;chr&gt; &lt;int&gt; ## 1 one-stage 22 ## 2 group-sequential 1429 ## 3 two-stage 1913 We then check via simulations of the test statistic, that the type I error and power constraints are fulfilled. tbl_designs %&gt;% transmute( type, toer = purrr::map(tbl_designs$optimal, ~sim_pr_reject(.[[1]], .0, datadist)$prob), power = purrr::map(tbl_designs$optimal, ~sim_pr_reject(.[[1]], theta , datadist)$prob) ) %&gt;% unnest(., cols = c(toer, power)) %&gt;% {print(.); .} %&gt;% { testthat::expect_true(all(.$toer &lt;= alpha * (1 + tol))) testthat::expect_true(all(.$power &gt;= min_power * (1 - tol))) } ## # A tibble: 3 × 3 ## type toer power ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage 0.0503 0.799 ## 2 group-sequential 0.0502 0.798 ## 3 two-stage 0.0500 0.799 The sample size function \\(n_2\\) should be monotonously decreasing. testthat::expect_true( all(diff( # get optimal two-stage design n2 pivots tbl_designs %&gt;% filter(type == &quot;two-stage&quot;) %&gt;% {.[[&quot;optimal&quot;]][[1]]$design@n2_pivots} ) &lt; 0) ) Since the degrees of freedom of the three design classes are ordered as ‘two-stage’ &gt; ‘group-sequential’ &gt; ‘one-stage’, the expected sample sizes (under the alternative) should be ordered in reverse (‘two-stage’ smallest). Additionally, expected sample sizes under both null and alternative are computed both via evaluate() and simulation-based. ess0 &lt;- ExpectedSampleSize(datadist, H_0) tbl_designs %&gt;% mutate( ess = map_dbl(optimal, ~evaluate(ess, .$design) ), ess_sim = map_dbl(optimal, ~sim_n(.$design, theta, datadist)$n ), ess0 = map_dbl(optimal, ~evaluate(ess0, .$design) ), ess0_sim = map_dbl(optimal, ~sim_n(.$design, .0, datadist)$n ) ) %&gt;% {print(.); .} %&gt;% { # sim/evaluate same under alternative? testthat::expect_equal(.$ess, .$ess_sim, tolerance = tol_n, scale = 1) # sim/evaluate same under null? testthat::expect_equal(.$ess0, .$ess0_sim, tolerance = tol_n, scale = 1) # monotonicity with respect to degrees of freedom testthat::expect_true(all(diff(.$ess) &lt; 0)) } ## # A tibble: 3 × 7 ## type initial optimal ess ess_sim ess0 ess0_sim ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 one-stage &lt;OnStgDsg&gt; &lt;adptrOpR [3]&gt; 121 121 121 121 ## 2 group-sequential &lt;GrpSqntD&gt; &lt;adptrOpR [3]&gt; 111. 111. 103. 103. ## 3 two-stage &lt;TwStgDsg&gt; &lt;adptrOpR [3]&gt; 111. 111. 104. 105. The expected sample size under the alternative of the optimized designs should be lower than the sample size of the initial designs. testthat::expect_lte( evaluate(ess, tbl_designs %&gt;% pull(optimal) %&gt;% .[[1]] %&gt;% .$design ), evaluate(ess, tbl_designs %&gt;% pull(initial) %&gt;% .[[1]] ) ) "],["scenario-xii-using-further-constraints.html", "13 Scenario XII: Using further constraints 13.1 General assumptions 13.2 Constraint X-1: Maximal Sample Size", " 13 Scenario XII: Using further constraints 13.1 General assumptions adoptr offers the possibility to use a variety of further constraints. This chapter is dedicated to show a first scenario in which further conditions on the trial need to be met. We assume a classical two-arm trial with normal test statistic and known variance. The null hypothesis is given by \\(\\mathcal{H}_0: \\delta \\leq 0\\) and the alternative is assumed to be an effect size of \\(\\delta=0.5\\) with point prior distribution. The type one error rate should be lower than \\(\\alpha=0.025\\) and the power at the alternative must be at least \\(0.9\\). The objective function to be minimized is the expected sample size under the alternative, i.e. \\(\\boldsymbol{E}\\big[n(\\mathcal{D})\\big]\\). datadist &lt;- Normal(two_armed = TRUE) H_0 &lt;- PointMassPrior(.0, 1) prior &lt;- PointMassPrior(0.5, 1) alpha &lt;- 0.025 min_power &lt;- 0.9 toer_cnstr &lt;- Power(datadist, H_0) &lt;= alpha pow_cnstr &lt;- Power(datadist, prior) &gt;= min_power ess &lt;- ExpectedSampleSize(datadist, prior) 13.2 Constraint X-1: Maximal Sample Size 13.2.1 Details Even though the expected sample size of adaptive two-stage designs is generally lower than the expected sample size of classical one-stage designs, it is possible that the sample size of two-stage designs exceeds the sample size of one-stage designs in some cases. Thus, it is not absurd to assume that the maximum sample size should have an upper bound. We say this upper bound is given by \\(120\\). smplsize_cnstr &lt;- MaximumSampleSize() &lt;= 120 13.2.2 Initial Designs As an initial design, we choose the adoptr-function get_initial_design(). init_twostage &lt;- get_initial_design(0.5, alpha, 1 - min_power, type_design = &quot;two-stage&quot;, dist = datadist) 13.2.3 Optimization opt_twostage_cnstr &lt;- minimize(ess, subject_to(toer_cnstr, pow_cnstr, smplsize_cnstr), initial_design = init_twostage) 13.2.4 Testcases At first, we verify the type one error rate and power constraints by simulation: toer &lt;- sim_pr_reject(opt_twostage_cnstr$design, 0.0, datadist) power &lt;- sim_pr_reject(opt_twostage_cnstr$design, 0.5, datadist) testthat::expect_true(toer$prob &lt;= alpha * (1 + tol)) testthat::expect_true(power$prob &gt;= min_power * (1 - tol)) We now check that the maximal sample size is always smaller than \\(118\\): testthat::expect_true(evaluate(MaximumSampleSize(), opt_twostage_cnstr$design) &lt;= 120) Since we added a constraint to our minimization problem, the expected sample size of this design should be higher than the expected sample size without the constraint on the maximum sample size. opt_twostage &lt;- minimize(ess,subject_to(toer_cnstr,pow_cnstr),initial_design = init_twostage) testthat::expect_true(evaluate(ess,opt_twostage_cnstr$design)&gt;= evaluate(ess,opt_twostage$design)) "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
