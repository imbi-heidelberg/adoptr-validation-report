# Scenario I: large effect, point prior {#scenarioI}


## Details

In this scenario, a classical two-arm trial with normal test statistic and
known variance (w.l.o.g. variance of the test statistic is 1).
This situation corresponds to a classical $z$-test for a difference in 
population means.
The null hypothesis is no population mean difference, i.e., 
$\mathcal{H}_0:\delta \leq 0$.
An alternative effect size of $\delta = 0.4$ with point prior distribution is 
assumed. 
Across all variants in this scenario, the one-sided maximal type one error rate 
is kept constant at $\alpha=0.025$ and the power at the point alternative of 
$\delta=0.4$ must be at least $0.8$.

```{r}
# data distribution and hypotheses
datadist   <- Normal(two_armed = TRUE)
H_0        <- PointMassPrior(.0, 1)
prior      <- PointMassPrior(.4, 1)

# define constraints
alpha      <- 0.025
min_power  <- 0.8
toer_cnstr <- Power(datadist, H_0) <= alpha
pow_cnstr  <- Power(datadist, prior) >= min_power
```



## Variant I-1: Minimizing Expected Sample Size under Point Prior {#variantI_1}

### Objective

Expected sample size under the respective prior is minimized, i.e.,
$\boldsymbol{E}\big[n(\mathcal{D})\big]$.
```{r}
ess <- ExpectedSampleSize(datadist, prior)
```


### Constrains

No additional constraints are considered in this variant.


### Initial Design

`adoptr` requires the definition of an initial design for optimization. 
We start with a group-sequential design from the package `rpact` that
fulfills these constraints and is used later for comparison.
```{r}
order          <- 7L
init_design_gs <- rpact_design(0.4, 0.025, 0.8, TRUE, order)
```


### Optimization 

The optimal design is computed in three variants:

1. one-stage design respectively
2. group-sequential (constant stage-two sample size)
3. generic two-stage

```{r}
opt_design <- function(initial_design) {
    minimize(
        ess,
        subject_to(
            toer_cnstr,
            pow_cnstr
        ),
        initial_design = initial_design,
        opts = opts
    )
}

# one stage design:
opt1_os <- opt_design(OneStageDesign(200, 2.0))

# group sequential design:
opt1_gs <- opt_design(init_design_gs)

# generic two-stage design:
opt1_ts <- opt_design(TwoStageDesign(init_design_gs))
```



### Test Cases


Check if the optimization algorithm converged in all cases:
```{r}
iters <- sapply(list(opt1_ts, opt1_gs, opt1_os), function(x) x$nloptr_return$iterations)
testthat::expect_true(all(iters < opts$maxeval))
print(iters)
```


Simulate type-one-error-rate for all three designs and check vs. constraint:
```{r}
tmp     <- sapply(list(opt1_ts, opt1_gs, opt1_os),  
                  function(x) sim_pr_reject(x$design, .0, datadist))
df_toer <- data.frame(toer = as.numeric(tmp[1, ]), se = as.numeric(tmp[2, ]))
testthat::expect_true(all(df_toer$toer <= alpha * (1 + tol)))
print(df_toer)
```


Simulate power and make sure constraint is satisfied ina ll cases:
```{r}
tmp     <- sapply(list(opt1_ts, opt1_gs, opt1_os),  
                  function(x) sim_pr_reject(x$design, .4, datadist))
df_pow  <- data.frame(pow  = as.numeric(tmp[1, ]), se   = as.numeric(tmp[2, ]))
testthat::expect_true(all(df_pow$pow >= min_power * (1 - tol)))
print(df_pow)
```


The $n_2$ function of the optimal two-stage design is monotonously decreasing:
```{r}
expect_equal(
    sign(diff(opt1_ts$design@n2_pivots)),
    rep(-1, (order - 1))
)
```



The expected sample sizes of the optimal designs must be decreasing with 
increasing flexibility: one-stage > group-sequential > generic two-stage:
```{r}
ess_values <- sapply(
  list(OS = opt1_os, GS = opt1_gs, TS = opt1_ts), 
  function(x) evaluate(ess, x$design))
testthat::expect_true(all(diff(ess_values) <= 0))
ess_values
```



Check simulated sample size vs. computed:
The expected sample size of the optimal designs is simulated and compared
to the outcome of `adoptr::evaluate()`.
```{r}
ess_0 <- ExpectedSampleSize(datadist, H_0)
ess_0_values <- sapply(
  list(OS = opt1_os, GS = opt1_gs, TS = opt1_ts), 
  function(x) evaluate(ess0, x$design))
expect_equal(
    sim_n(opt1_os$design, .0, datadist)$n,
    evaluate(ess_0, opt1_os$design),
    tolerance = tol_n,
    scale = 1
)

expect_equal(
    sim_n(opt1_gs$design, .0, datadist)$n,
    evaluate(ess_0, opt1_gs$design),
    tolerance = tol_n,
    scale = 1
)

expect_equal(
    sim_n(opt1_ts$design, .0, datadist)$n,
    evaluate(ess_0, opt1_ts$design),
    tolerance = tol_n,
    scale = 1
)
```


Additionally, the sample sizes under the point prior are compared.
```{r}
expect_equal(
    sim_n(opt1_os$design, .4, datadist)$n,
    evaluate(ess, opt1_os$design),
    tolerance = tol_n,
    scale = 1
)

expect_equal(
    sim_n(opt1_gs$design, .4, datadist)$n,
    evaluate(ess, opt1_gs$design),
    tolerance = tol_n,
    scale = 1
)

expect_equal(
    sim_n(opt1_ts$design, .4, datadist)$n,
    evaluate(ess, opt1_ts$design),
    tolerance = tol_n,
    scale = 1
)
```






## Variant I-2: Minimizing Expected Sample Size under Null Hypothesis {#variantI_2}

### Objective

Expected sample size under the null hypothesis prior is minimized, i.e.,
```{r}
ess_0 <- ExpectedSampleSize(datadist, H_0)
```


### Constrains

The constraints remain the same as before.

### Initial Design

For run time issues the previous initial design has to be updated.
It turns out that a constant $c_2$-starting vector is much more efficient
in this case.
Furthermore, a more strict upper-boundary design than the default one needs
to be defined because stopping for efficacy would otherwise only happen
for very large values of $x_1$ due to optimization under the null hypothesis.

```{r}
init_design_2 <- init_design
init_design_2@c2_pivots <- rep(2, order)


ub_design <- TwoStageDesign(
    opt1_os$design@n1,
    opt1_os$design@c1f,
    3,
    rep(300, order),
    rep(3.0, order)
)
```

### Optimization 

The optimal two-stage design is computed. 

```{r}
opt2_ts <- minimize(
        ess_0,
        subject_to(
            toer_cnstr,
            pow_cnstr
        ),
        initial_design = init_design_2,
        upper_boundary_design = ub_design,
        opts = opts
)
```



### Test Cases

Check if the optimization algorithm converged.
```{r}
print(opt2_ts$nloptr_return$iterations)

testthat::expect_true(opt2_ts$nloptr_return$iterations < opts$maxeval)
```

The $n_2$ function of the optimal two-stage design is expected to be 
monotonously increasing.
```{r}
expect_equal(
    sign(diff(opt2_ts$design@n2_pivots)),
    rep(1, (order - 1))
)
```


Type one error rate constraint is tested for the optimal design.
Due to numerical issues we allow a relative error of $1\%$.
```{r}
tmp     <- sim_pr_reject(opt2_ts$design, .0, datadist)
df_toer2 <- data.frame(
    toer = as.numeric(tmp[1]),
    se   = as.numeric(tmp[2])
)
rm(tmp)

testthat::expect_true(all(df_toer2$toer <= alpha * (1 + tol)))

df_toer2
```


The power constraint can also be tested via simulation.
Due to numerical issues we allow a relative error of $1\%$.
```{r}
tmp     <- sim_pr_reject(opt2_ts$design, .4, datadist)
df_pow2 <- data.frame(
    pow  = as.numeric(tmp[1]),
    se   = as.numeric(tmp[2])
)
rm(tmp)

testthat::expect_true(all(df_pow2$pow >= min_power * (1 - tol)))

df_pow2
```

The expected sample size under the null should be lower than the ESS under the
null of the initial design derived from `rpact`.
```{r}
testthat::expect_gte(
    evaluate(ess_0, init_design),
    evaluate(ess_0, opt2_ts$design)
)
```


The expected sample size of the optimal designs is simulated and compared
to the outcome of `adoptr::evaluate()`.
The tolerance is set to $0.5$ what is due to rounding one patient per group
in the worst case.
```{r}
expect_equal(
    sim_n(opt2_ts$design, .0, datadist)$n,
    evaluate(ess_0, opt2_ts$design),
    tolerance = tol_n,
    scale = 1
)
```


Additionally, the sample sizes under the point prior are compared.
```{r}
expect_equal(
    sim_n(opt2_ts$design, .4, datadist)$n,
    evaluate(ess, opt2_ts$design),
    tolerance = tol_n,
    scale = 1
)
```




## Variant I-3: Conditional Power Constraint {#variantI_3}

### Objective

Expected sample size under the point prior is minimized and has already been 
defined.

### Constrains

The constraints remain the same as before, additionally to a constraint
on conditional power.
```{r}
cp <- ConditionalPower(datadist, prior)

cp_cnstr <- cp >= .7
```

### Initial Design

The previous initial design can still be applied.

### Optimization 

The optimal two-stage design is computed. 

```{r}
opt3_ts <- minimize(
        ess,
        subject_to(
            toer_cnstr,
            pow_cnstr,
            cp_cnstr
        ),
        initial_design = init_design,
        opts = opts
)
```



### Test Cases

Check if the optimization algorithm converged.
```{r}
print(opt3_ts$nloptr_return$iterations)

testthat::expect_true(opt3_ts$nloptr_return$iterations < opts$maxeval)
```


Type one error rate constraint is tested for the optimal design.
```{r}
tmp     <- sim_pr_reject(opt3_ts$design, .0, datadist)
df_toer3 <- data.frame(
    toer = as.numeric(tmp[1]),
    se   = as.numeric(tmp[2])
)
rm(tmp)

testthat::expect_true(all(df_toer3$toer <= alpha * (1 + tol)))

df_toer3
```


The power constraint can also be tested via simulation.
Due to numerical issues we allow a relative error of $1\%$.
```{r}
tmp     <- sim_pr_reject(opt3_ts$design, .4, datadist)
df_pow3 <- data.frame(
    pow  = as.numeric(tmp[1]),
    se   = as.numeric(tmp[2])
)
rm(tmp)

testthat::expect_true(all(df_pow3$pow >= min_power * (1 - tol)))

df_pow3
```


The conditional power constraint needs to be tested. 
Select three points for this and check the constraint.
```{r}
x <- adoptr:::scaled_integration_pivots(opt3_ts$design)[c(1, 3, 5)]

cp_val <- sapply(x, function(z) evaluate(cp, opt3_ts$design, z))

testthat::expect_true(all(cp_val >= 0.7 * (1 - tol)))
```


Simulate conditional power at the three pivots and check if the 
constraint is fulfilled with a relative tolerance of $1\%$.
```{r}
cp_sim <- function(z) {
  z2  <- simulate(datadist, 10^6, n2(opt3_ts$design, z), .4, 42)
  rej <- ifelse(z2 > c2(opt3_ts$design, z), 1, 0)
  return(mean(rej))
}

cp_sim_val <- sapply(x, function(z) cp_sim(z))

testthat::expect_true(all(cp_sim_val >= (0.7) * (1 - tol)))
```


The expected sample size under the prior should be higher than
in the case without the constraint that was analyzed in I.1.
```{r}
testthat::expect_gte(
    evaluate(ess, opt3_ts$design),
    evaluate(ess, opt1_ts$design)
)
```





## Plot Two-Stage Designs
The optimal two-stage designs stemming from the different variants
are plotted together. 


```{r, echo = FALSE}
z1 <- seq(0, 4, by = .01)

tibble(
    type  = c("ESS under Prior", "ESS under Null", "ESS under Prior with CP constraint"), 
    design = list(opt1_ts$design, opt2_ts$design, opt3_ts$design)
) %>% 
    group_by(type) %>% 
    do(
        z1 = z1,
        n  = adoptr::n(.$design[[1]], z1),
        c2 = c2(.$design[[1]], z1),
        cp = evaluate(cp, .$design[[1]], z1)
    ) %>% 
    unnest() %>% 
    mutate(
        section = ifelse(
            is.finite(c2), 
            "continuation", 
            ifelse(c2 == -Inf, "efficacy", "futility")
        )
    ) %>% 
    gather(variable, value, n, c2, cp) %>% 
    ggplot(aes(z1, value, color = type)) +
        geom_line(aes(group = interaction(section, type))) + 
        facet_wrap(~variable, scales = "free_y") +
        theme_bw() +
        scale_color_manual(
          values = c(rgb(0,74,111, maxColorValue = 255),
                                    rgb(0,159,227, maxColorValue = 255),
                                    rgb(230,121,0, maxColorValue = 255))) +
        theme(
            panel.grid = element_blank(),
            legend.position = "bottom"
        )
```

